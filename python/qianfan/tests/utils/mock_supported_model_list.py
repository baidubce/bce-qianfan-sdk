_MOCK_SUPPORTED_MODEL_LIST_JSON = """
{"requestId": "4a3036fe-6a53-4d8f-8406-209f138373a9", "result": [{"baseModel": "Custom Model", "model": "Custom-Model", "modelType": "Text2Text", "supportTrainMode": [{"trainMode": "SFT", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-10, 0.0002], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "schedulerName", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "cosine", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.1], "default": 0.03, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.001, 1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}], "supportIdleResource": false}]}]}, {"baseModel": "ERNIE BLM", "model": "ERNIE-BLM-4K", "modelType": "Text2Text", "supportTrainMode": [{"trainMode": "SFT", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 3e-05, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "pseudoSamplingProb", "type": "float", "checkType": "range", "checkValue": [0, 0.9], "default": 0, "name": "伪多轮概率", "description": "伪多轮概率（Pseudo Multi-Round Probability），随机采用数据拼接的数据增强策略的概率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 2, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 4, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-06, 0.001], "default": 0.0003, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [2, 4, 8], "default": 8, "name": "LoRA 策略中的秩", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "loraAllLinear", "type": "string", "checkType": "choice", "checkValue": ["True", "False"], "default": "True", "name": "LoRA所有线性层", "description": "LoRA所有线性层（LoRA in Linear）,是否将 LoRA 策略应用在所有Linear层。如果资源充足且目标是最大程度地提升模型性能，可以尝试在所有线性层上应用 LoRA，但需注意监控过拟合风险。"}, {"key": "pseudoSamplingProb", "type": "float", "checkType": "range", "checkValue": [0, 0.9], "default": 0, "name": "伪多轮概率", "description": "伪多轮概率（Pseudo Multi-Round Probability），随机采用数据拼接的数据增强策略的概率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 8, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}, {"trainMode": "DPO", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "dpoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "lossType", "type": "string", "checkType": "choice", "checkValue": ["sigmoid", "ipo", "kto_pair"], "default": "sigmoid", "name": "DPO偏好损失类型", "description": "DPO中偏好损失类型（Loss Type)，可选择的类型包括sigmoid、ipo、kto_pair。sigmoid适用于一般情况，提供稳定训练过程，ipo可以纠正模型过度自信的问题，kto可以使模型更符合用户偏好。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 4, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 2, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage2", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "dpoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [2, 4, 8], "default": 8, "name": "LoRA 策略中的秩", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "lossType", "type": "string", "checkType": "choice", "checkValue": ["sigmoid", "ipo", "kto_pair"], "default": "sigmoid", "name": "DPO偏好损失类型", "description": "DPO中偏好损失类型（Loss Type)，可选择的类型包括sigmoid、ipo、kto_pair。sigmoid适用于一般情况，提供稳定训练过程，ipo可以纠正模型过度自信的问题，kto可以使模型更符合用户偏好。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 8, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}, {"trainMode": "KTO", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "ktoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 4, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 2, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage2", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "ktoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [2, 4, 8], "default": 8, "name": "LoRA 策略中的秩", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 8, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}]}, {"baseModel": "ERNIE BLM", "model": "ERNIE-BLM-Pro-8K", "modelType": "Text2Text", "supportTrainMode": [{"trainMode": "SFT", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 3e-05, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "pseudoSamplingProb", "type": "float", "checkType": "range", "checkValue": [0, 0.9], "default": 0, "name": "伪多轮概率", "description": "伪多轮概率（Pseudo Multi-Round Probability），随机采用数据拼接的数据增强策略的概率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 8, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 1, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-06, 0.001], "default": 0.0003, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [8, 64], "default": 64, "name": "LoRA 策略中的秩", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "loraAllLinear", "type": "string", "checkType": "choice", "checkValue": ["True", "False"], "default": "True", "name": "LoRA所有线性层", "description": "LoRA所有线性层（LoRA in Linear）,是否将 LoRA 策略应用在所有Linear层。如果资源充足且目标是最大程度地提升模型性能，可以尝试在所有线性层上应用 LoRA，但需注意监控过拟合风险。"}, {"key": "pseudoSamplingProb", "type": "float", "checkType": "range", "checkValue": [0, 0.9], "default": 0, "name": "伪多轮概率", "description": "伪多轮概率（Pseudo Multi-Round Probability），随机采用数据拼接的数据增强策略的概率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 4, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 2, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}, {"trainMode": "DPO", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "dpoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "lossType", "type": "string", "checkType": "choice", "checkValue": ["sigmoid", "ipo", "kto_pair"], "default": "sigmoid", "name": "DPO偏好损失类型", "description": "DPO中偏好损失类型（Loss Type)，可选择的类型包括sigmoid、ipo、kto_pair。sigmoid适用于一般情况，提供稳定训练过程，ipo可以纠正模型过度自信的问题，kto可以使模型更符合用户偏好。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 8, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 1, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "dpoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [8, 64], "default": 64, "name": "LoRA 策略中的秩", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "lossType", "type": "string", "checkType": "choice", "checkValue": ["sigmoid", "ipo", "kto_pair"], "default": "sigmoid", "name": "DPO偏好损失类型", "description": "DPO中偏好损失类型（Loss Type)，可选择的类型包括sigmoid、ipo、kto_pair。sigmoid适用于一般情况，提供稳定训练过程，ipo可以纠正模型过度自信的问题，kto可以使模型更符合用户偏好。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 4, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 2, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}, {"trainMode": "KTO", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "ktoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 8, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 1, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "ktoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [8, 64], "default": 64, "name": "LoRA 策略中的秩", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 4, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 2, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}]}, {"baseModel": "ERNIE BLM", "model": "ERNIE-BLM-Chat-8K", "modelType": "Text2Text", "supportTrainMode": [{"trainMode": "SFT", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 3e-05, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "pseudoSamplingProb", "type": "float", "checkType": "range", "checkValue": [0, 0.9], "default": 0, "name": "伪多轮概率", "description": "伪多轮概率（Pseudo Multi-Round Probability），随机采用数据拼接的数据增强策略的概率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 8, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 1, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-06, 0.001], "default": 0.0003, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [8, 64], "default": 64, "name": "LoRA 策略中的秩", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "loraAllLinear", "type": "string", "checkType": "choice", "checkValue": ["True", "False"], "default": "True", "name": "LoRA所有线性层", "description": "LoRA所有线性层（LoRA in Linear）,是否将 LoRA 策略应用在所有Linear层。如果资源充足且目标是最大程度地提升模型性能，可以尝试在所有线性层上应用 LoRA，但需注意监控过拟合风险。"}, {"key": "pseudoSamplingProb", "type": "float", "checkType": "range", "checkValue": [0, 0.9], "default": 0, "name": "伪多轮概率", "description": "伪多轮概率（Pseudo Multi-Round Probability），随机采用数据拼接的数据增强策略的概率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 4, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 2, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}, {"trainMode": "DPO", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "dpoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "lossType", "type": "string", "checkType": "choice", "checkValue": ["sigmoid", "ipo", "kto_pair"], "default": "sigmoid", "name": "DPO偏好损失类型", "description": "DPO中偏好损失类型（Loss Type)，可选择的类型包括sigmoid、ipo、kto_pair。sigmoid适用于一般情况，提供稳定训练过程，ipo可以纠正模型过度自信的问题，kto可以使模型更符合用户偏好。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 8, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 1, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "dpoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [8, 64], "default": 64, "name": "LoRA 策略中的秩", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "lossType", "type": "string", "checkType": "choice", "checkValue": ["sigmoid", "ipo", "kto_pair"], "default": "sigmoid", "name": "DPO偏好损失类型", "description": "DPO中偏好损失类型（Loss Type)，可选择的类型包括sigmoid、ipo、kto_pair。sigmoid适用于一般情况，提供稳定训练过程，ipo可以纠正模型过度自信的问题，kto可以使模型更符合用户偏好。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 4, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 2, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}, {"trainMode": "KTO", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "ktoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 8, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 1, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "ktoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [8, 64], "default": 64, "name": "LoRA 策略中的秩", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 4, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 2, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}]}, {"baseModel": "ERNIE BLM", "model": "ERNIE-BLM-Tiny-8K", "modelType": "Text2Text", "supportTrainMode": [{"trainMode": "SFT", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 3e-05, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 32, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "pseudoSamplingProb", "type": "float", "checkType": "range", "checkValue": [0, 0.9], "default": 0, "name": "伪多轮概率", "description": "伪多轮概率（Pseudo Multi-Round Probability），随机采用数据拼接的数据增强策略的概率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 8, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-06, 0.001], "default": 0.0003, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 32, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [2, 4, 8], "default": 8, "name": "LoRA 策略中的秩", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "loraAllLinear", "type": "string", "checkType": "choice", "checkValue": ["True", "False"], "default": "True", "name": "LoRA所有线性层", "description": "LoRA所有线性层（LoRA in Linear）,是否将 LoRA 策略应用在所有Linear层。如果资源充足且目标是最大程度地提升模型性能，可以尝试在所有线性层上应用 LoRA，但需注意监控过拟合风险。"}, {"key": "pseudoSamplingProb", "type": "float", "checkType": "range", "checkValue": [0, 0.9], "default": 0, "name": "伪多轮概率", "description": "伪多轮概率（Pseudo Multi-Round Probability），随机采用数据拼接的数据增强策略的概率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 8, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 2, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}, {"trainMode": "DPO", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 32, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "dpoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "lossType", "type": "string", "checkType": "choice", "checkValue": ["sigmoid", "ipo", "kto_pair"], "default": "sigmoid", "name": "DPO偏好损失类型", "description": "DPO中偏好损失类型（Loss Type)，可选择的类型包括sigmoid、ipo、kto_pair。sigmoid适用于一般情况，提供稳定训练过程，ipo可以纠正模型过度自信的问题，kto可以使模型更符合用户偏好。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 8, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 32, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "dpoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [2, 4, 8], "default": 8, "name": "LoRA 策略中的秩", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "lossType", "type": "string", "checkType": "choice", "checkValue": ["sigmoid", "ipo", "kto_pair"], "default": "sigmoid", "name": "DPO偏好损失类型", "description": "DPO中偏好损失类型（Loss Type)，可选择的类型包括sigmoid、ipo、kto_pair。sigmoid适用于一般情况，提供稳定训练过程，ipo可以纠正模型过度自信的问题，kto可以使模型更符合用户偏好。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 1, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 2, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}, {"trainMode": "KTO", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 32, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "ktoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 8, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 32, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "ktoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [2, 4, 8], "default": 8, "name": "LoRA 策略中的秩", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 1, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 2, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}]}, {"baseModel": "ERNIE BLM", "model": "ERNIE-BLM-Lite-Pro-8K", "modelType": "Text2Text", "supportTrainMode": [{"trainMode": "SFT", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 3e-05, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 32, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "pseudoSamplingProb", "type": "float", "checkType": "range", "checkValue": [0, 0.9], "default": 0, "name": "伪多轮概率", "description": "伪多轮概率（Pseudo Multi-Round Probability），随机采用数据拼接的数据增强策略的概率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数；为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 8, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 4, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 1, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}]}, {"baseModel": "ERNIE BLM", "model": "ERNIE-BLM-Lite-8K-1018", "modelType": "Text2Text", "supportTrainMode": [{"trainMode": "SFT", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 3e-05, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [4096, 8192], "default": 8192, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "pseudoSamplingProb", "type": "float", "checkType": "range", "checkValue": [0, 0.9], "default": 0, "name": "伪多轮概率", "description": "伪多轮概率（Pseudo Multi-Round Probability），随机采用数据拼接的数据增强策略的概率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 2, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 4, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage2", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-06, 0.001], "default": 0.0003, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [4096, 8192], "default": 8192, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [2, 4, 8], "default": 8, "name": "LoRA 策略中的秩", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "loraAllLinear", "type": "string", "checkType": "choice", "checkValue": ["True", "False"], "default": "True", "name": "LoRA所有线性层", "description": "LoRA所有线性层（LoRA in Linear）,是否将 LoRA 策略应用在所有Linear层。如果资源充足且目标是最大程度地提升模型性能，可以尝试在所有线性层上应用 LoRA，但需注意监控过拟合风险。"}, {"key": "pseudoSamplingProb", "type": "float", "checkType": "range", "checkValue": [0, 0.9], "default": 0, "name": "伪多轮概率", "description": "伪多轮概率（Pseudo Multi-Round Probability），随机采用数据拼接的数据增强策略的概率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 2, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 4, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}, {"trainMode": "DPO", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [4096, 8192], "default": 8192, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "dpoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "lossType", "type": "string", "checkType": "choice", "checkValue": ["sigmoid", "ipo", "kto_pair"], "default": "sigmoid", "name": "DPO偏好损失类型", "description": "DPO中偏好损失类型（Loss Type)，可选择的类型包括sigmoid、ipo、kto_pair。sigmoid适用于一般情况，提供稳定训练过程，ipo可以纠正模型过度自信的问题，kto可以使模型更符合用户偏好。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 8, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage2", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 1, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "dpoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [2, 4, 8], "default": 8, "name": "LoRA 策略中的秩", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "lossType", "type": "string", "checkType": "choice", "checkValue": ["sigmoid", "ipo", "kto_pair"], "default": "sigmoid", "name": "DPO偏好损失类型", "description": "DPO中偏好损失类型（Loss Type)，可选择的类型包括sigmoid、ipo、kto_pair。sigmoid适用于一般情况，提供稳定训练过程，ipo可以纠正模型过度自信的问题，kto可以使模型更符合用户偏好。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 2, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 4, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}, {"trainMode": "KTO", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [4096, 8192], "default": 8192, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "ktoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 8, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage2", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 1, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [4096, 8192], "default": 8192, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "ktoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [2, 4, 8], "default": 8, "name": "LoRA 策略中的秩", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 2, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 4, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}]}, {"baseModel": "ERNIE Speed", "model": "ERNIE-Speed-8K", "modelType": "Text2Text", "supportTrainMode": [{"trainMode": "SFT", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 3e-05, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "pseudoSamplingProb", "type": "float", "checkType": "range", "checkValue": [0, 0.9], "default": 0, "name": "伪多轮概率", "description": "伪多轮概率（Pseudo Multi-Round Probability），随机采用数据拼接的数据增强策略的概率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 8, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 1, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-06, 0.001], "default": 0.0003, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [8, 64], "default": 64, "name": "LoRA 策略中的秩", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "loraAllLinear", "type": "string", "checkType": "choice", "checkValue": ["True", "False"], "default": "True", "name": "LoRA所有线性层", "description": "LoRA所有线性层（LoRA in Linear）,是否将 LoRA 策略应用在所有Linear层。如果资源充足且目标是最大程度地提升模型性能，可以尝试在所有线性层上应用 LoRA，但需注意监控过拟合风险。"}, {"key": "pseudoSamplingProb", "type": "float", "checkType": "range", "checkValue": [0, 0.9], "default": 0, "name": "伪多轮概率", "description": "伪多轮概率（Pseudo Multi-Round Probability），随机采用数据拼接的数据增强策略的概率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 4, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 2, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}, {"trainMode": "PostPretrain", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 3e-05, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度。超过该长度的数据在训练将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 32, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 8, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 1, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": false}]}, {"trainMode": "DPO", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "dpoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "lossType", "type": "string", "checkType": "choice", "checkValue": ["sigmoid", "ipo", "kto_pair"], "default": "sigmoid", "name": "DPO偏好损失类型", "description": "DPO中偏好损失类型（Loss Type)，可选择的类型包括sigmoid、ipo、kto_pair。sigmoid适用于一般情况，提供稳定训练过程，ipo可以纠正模型过度自信的问题，kto可以使模型更符合用户偏好。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 8, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 1, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}, {"trainMode": "KTO", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "ktoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 8, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 1, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "ktoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [8, 64], "default": 64, "name": "LoRA 策略中的秩", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 4, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 2, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}, {"trainMode": "SimPO", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "simpoBeta", "type": "float", "checkType": "range", "checkValue": [2, 2.5], "default": 2, "name": "温度超参", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "simpoGamma", "type": "float", "checkType": "range", "checkValue": [0.01, 1.5], "default": 0.5, "name": "边距超参", "description": "边距超参(Gamma)，SimPO目标奖励边距超参数。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数；为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 8, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 1, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}]}, {"baseModel": "ERNIE Speed", "model": "ERNIE-Speed-Pro-128K", "modelType": "Text2Text", "supportTrainMode": [{"trainMode": "SFT", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 3e-05, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [16384, 32768, 65536, 131072], "default": 32768, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "pseudoSamplingProb", "type": "float", "checkType": "range", "checkValue": [0, 0.9], "default": 0, "name": "伪多轮概率", "description": "伪多轮概率（Pseudo Multi-Round Probability），随机采用数据拼接的数据增强策略的概率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 8, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 1, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage2", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 1, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-06, 0.001], "default": 0.0003, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [16384, 32768, 65536, 131072], "default": 32768, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [8, 64], "default": 64, "name": "LoRA 策略中的秩", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "loraAllLinear", "type": "string", "checkType": "choice", "checkValue": ["True", "False"], "default": "True", "name": "LoRA所有线性层", "description": "LoRA所有线性层（LoRA in Linear）,是否将 LoRA 策略应用在所有Linear层。如果资源充足且目标是最大程度地提升模型性能，可以尝试在所有线性层上应用 LoRA，但需注意监控过拟合风险。"}, {"key": "pseudoSamplingProb", "type": "float", "checkType": "range", "checkValue": [0, 0.9], "default": 0, "name": "伪多轮概率", "description": "伪多轮概率（Pseudo Multi-Round Probability），随机采用数据拼接的数据增强策略的概率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 8, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 1, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage2", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 1, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}, {"trainMode": "DPO", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [16384, 32768, 65536, 131072], "default": 32768, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "dpoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "lossType", "type": "string", "checkType": "choice", "checkValue": ["sigmoid", "ipo", "kto_pair"], "default": "sigmoid", "name": "DPO偏好损失类型", "description": "DPO中偏好损失类型（Loss Type)，可选择的类型包括sigmoid、ipo、kto_pair。sigmoid适用于一般情况，提供稳定训练过程，ipo可以纠正模型过度自信的问题，kto可以使模型更符合用户偏好。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 8, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 1, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage2", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 1, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [16384, 32768, 65536, 131072], "default": 32768, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "dpoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [8, 64], "default": 64, "name": "LoRA 策略中的秩", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "lossType", "type": "string", "checkType": "choice", "checkValue": ["sigmoid", "ipo", "kto_pair"], "default": "sigmoid", "name": "DPO偏好损失类型", "description": "DPO中偏好损失类型（Loss Type)，可选择的类型包括sigmoid、ipo、kto_pair。sigmoid适用于一般情况，提供稳定训练过程，ipo可以纠正模型过度自信的问题，kto可以使模型更符合用户偏好。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 8, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 1, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage2", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 1, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}, {"trainMode": "PostPretrain", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 3e-05, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [8192, 16384, 32768, 65536, 131072], "default": 32768, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度。超过该长度的数据在训练将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 8, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 1, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage2", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 1, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": false}]}, {"trainMode": "KTO", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [16384, 32768, 65536, 131072], "default": 32768, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "ktoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 8, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 1, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage2", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 1, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [16384, 32768, 65536, 131072], "default": 32768, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "ktoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [8, 64], "default": 64, "name": "LoRA 策略中的秩", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 8, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 1, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage2", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 1, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}, {"trainMode": "SimPO", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 3e-05, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [16384, 32768, 65536, 131072], "default": 32768, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "simpoBeta", "type": "float", "checkType": "range", "checkValue": [2, 2.5], "default": 2, "name": "温度超参", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "simpoGamma", "type": "float", "checkType": "range", "checkValue": [0.01, 1.5], "default": 0.5, "name": "边距超参", "description": "边距超参(Gamma)，SimPO目标奖励边距超参数。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 8, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 1, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage2", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 1, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}]}, {"baseModel": "ERNIE Lite", "model": "ERNIE-Lite-8K-0308", "modelType": "Text2Text", "supportTrainMode": [{"trainMode": "SFT", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 3e-05, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "pseudoSamplingProb", "type": "float", "checkType": "range", "checkValue": [0, 0.9], "default": 0, "name": "伪多轮概率", "description": "伪多轮概率（Pseudo Multi-Round Probability），随机采用数据拼接的数据增强策略的概率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 2, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 4, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage2", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-06, 0.001], "default": 0.0003, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [2, 4, 8], "default": 8, "name": "LoRA 策略中的秩", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "loraAllLinear", "type": "string", "checkType": "choice", "checkValue": ["True", "False"], "default": "True", "name": "LoRA所有线性层", "description": "LoRA所有线性层（LoRA in Linear）,是否将 LoRA 策略应用在所有Linear层。如果资源充足且目标是最大程度地提升模型性能，可以尝试在所有线性层上应用 LoRA，但需注意监控过拟合风险。"}, {"key": "pseudoSamplingProb", "type": "float", "checkType": "range", "checkValue": [0, 0.9], "default": 0, "name": "伪多轮概率", "description": "伪多轮概率（Pseudo Multi-Round Probability），随机采用数据拼接的数据增强策略的概率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 2, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 4, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}, {"trainMode": "DPO", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "dpoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "lossType", "type": "string", "checkType": "choice", "checkValue": ["sigmoid", "ipo", "kto_pair"], "default": "sigmoid", "name": "DPO偏好损失类型", "description": "DPO中偏好损失类型（Loss Type)，可选择的类型包括sigmoid、ipo、kto_pair。sigmoid适用于一般情况，提供稳定训练过程，ipo可以纠正模型过度自信的问题，kto可以使模型更符合用户偏好。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 8, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage2", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 1, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}, {"trainMode": "KTO", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "ktoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 8, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage2", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 1, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "ktoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [2, 4, 8], "default": 8, "name": "LoRA 策略中的秩", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 2, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 4, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}, {"trainMode": "RM", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "useCls", "type": "boolean", "checkType": "choice", "checkValue": [true, false], "default": true, "name": "useCls", "description": "特征是否选取cls token的位置。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "pseudoSamplingProb", "type": "float", "checkType": "range", "checkValue": [0, 0.9], "default": 0, "name": "伪多轮概率", "description": "伪多轮概率（Pseudo Multi-Round Probability），随机采用数据拼接的数据增强策略的概率。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数；为0时不开启验证，没有相关指标。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}], "supportIdleResource": false}]}, {"trainMode": "PPO", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "critic_learning_rate", "type": "float", "checkType": "range", "checkValue": [1e-07, 1e-05], "default": 2e-06, "name": "Critic学习率", "description": "Critic学习率（Learning Rate），是Critic模型在梯度下降的过程中更新权重时的超参数，过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 1e-05], "default": 1e-06, "name": "Actor学习率", "description": "Actor学习率（Learning Rate），是Actor模型在梯度下降的过程中更新权重时的超参数，过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "max_prompt_len_4k", "type": "int", "checkType": "range", "checkValue": [1024, 3072], "default": 2048, "name": "max_prompt_len_4k", "description": "max_prompt_len_4k (Prompt Length)，单条数据输入的最大长度，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "max_prompt_len_8k", "type": "int", "checkType": "range", "checkValue": [2048, 6144], "default": 2048, "name": "max_prompt_len_8k", "description": "max_prompt_len_8k (Prompt Length)，单条数据输入的最大长度，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "max_length_4k", "type": "int", "checkType": "range", "checkValue": [512, 2048], "default": 1024, "name": "max_length_4k", "description": "max_length_4k (response Length)，单条数据输出的最大长度，单位为token。max_length调大会增加生成时间，并且增加显存占用。max_length+max_prompt_len应当小于序列长度。"}, {"key": "max_length_8k", "type": "int", "checkType": "range", "checkValue": [512, 2048], "default": 1024, "name": "max_length_8k", "description": "max_length_8k (response Length)，单条数据输出的最大长度，单位为token。max_length调大会增加生成时间，并且增加显存占用。max_length+max_prompt_len应当小于序列长度。"}, {"key": "clip_range_score", "type": "int", "checkType": "range", "checkValue": [5, 50], "default": 10, "name": "clip_range_score", "description": "clip_range_score（Reward Clip），奖励分数裁剪阈值，用于限制actor和critic模型更新步幅，以保证模型更新的稳定性。调整该参数可以平衡模型更新的激进程度和训练稳定性。"}, {"key": "clip_range_value", "type": "int", "checkType": "range", "checkValue": [5, 50], "default": 5, "name": "clip_range_value", "description": "clip_range_value（PPO Critic Clip），用于限制critic模型预测新旧价值差值的裁剪阈值，以保证critic模型更新的稳定性。调整该参数可以平衡critic模型更新的激进程度和训练稳定性。"}, {"key": "clip_range_ratio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.3], "default": 0.2, "name": "clip_range_ratio", "description": "clip_range_ratio（PPO Actor Clip），用于控制actor模型更新的幅度，新旧策略的比值被裁剪到(1-clip_range_ratio,1+clip_range_ratio)范围。调整该参数可以平衡actor模型更新的激进程度和训练稳定性。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "top_p", "type": "float", "checkType": "range", "checkValue": [0, 1], "default": 0.9, "name": "top_p", "description": "top_p（Top P），用于控制模型生成文本时的创造性和随机性。调整 Top P 参数可以平衡文本的创新性和相关性。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数；为0时不开启验证，没有相关指标。"}, {"key": "repetition_penalty", "type": "float", "checkType": "range", "checkValue": [1, 2], "default": 1, "name": "repetition_penalty", "description": "repetition_penalty（Repetition Penalty），用于减少语言模型在文本生成过程中对已出现词汇的重复使用，以提高文本的多样性和连贯性。微调该参数可以平衡文本的流畅性和创新性。"}, {"key": "temperature", "type": "float", "checkType": "range", "checkValue": [0, 1], "default": 1, "name": "temperature", "description": "temperature（Temperature），用于调整语言模型输出概率分布的熵，影响生成文本的随机性和确定性。调整该参数可以平衡生成结果的确定性和多样性。"}, {"key": "kl_coeff", "type": "float", "checkType": "range", "checkValue": [0.001, 0.1], "default": 0.02, "name": "kl_coeff", "description": "kl_coeff（KL Coefficient），对reward增加增加KL-Penalty的系数。增大KL系数会使模型更紧密地逼近目标分布，减小生成文本的多样性；减小KL系数则允许模型生成更加多样化的文本，但可能偏离目标分布。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "choice", "checkValue": [64, 128, 256, 512, 1024, 2048, 4096], "default": 256, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}], "supportIdleResource": false}]}, {"trainMode": "SimPO", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "simpoBeta", "type": "float", "checkType": "range", "checkValue": [2, 2.5], "default": 2, "name": "温度超参", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "simpoGamma", "type": "float", "checkType": "range", "checkValue": [0.01, 1.5], "default": 0.5, "name": "边距超参", "description": "边距超参(Gamma)，SimPO目标奖励边距超参数。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数；为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 2, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 4, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage2", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}]}, {"baseModel": "ERNIE Lite", "model": "ERNIE-Lite-128K", "modelType": "Text2Text", "supportTrainMode": [{"trainMode": "RM", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [16384, 32768], "default": 32768, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 8, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "useCls", "type": "boolean", "checkType": "choice", "checkValue": [true, false], "default": true, "name": "useCls", "description": "特征是否选取cls token的位置。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "pseudoSamplingProb", "type": "float", "checkType": "range", "checkValue": [0, 0.9], "default": 0, "name": "伪多轮概率", "description": "伪多轮概率（Pseudo Multi-Round Probability），随机采用数据拼接的数据增强策略的概率。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数；为0时不开启验证，没有相关指标。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}], "supportIdleResource": false}]}, {"trainMode": "PPO", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "critic_learning_rate", "type": "float", "checkType": "range", "checkValue": [1e-07, 1e-05], "default": 2e-06, "name": "Critic学习率", "description": "Critic学习率（Learning Rate），是Critic模型在梯度下降的过程中更新权重时的超参数，过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 1e-05], "default": 1e-06, "name": "Actor学习率", "description": "Actor学习率（Learning Rate），是Actor模型在梯度下降的过程中更新权重时的超参数，过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [16384, 32768], "default": 32768, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 8, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "max_prompt_len_16k", "type": "int", "checkType": "range", "checkValue": [8192, 15360], "default": 15360, "name": "max_prompt_len_16k", "description": "max_prompt_len_16k (Prompt Length)，单条数据输入的最大长度，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "max_prompt_len_32k", "type": "int", "checkType": "range", "checkValue": [8192, 28672], "default": 28672, "name": "max_prompt_len_32k", "description": "max_prompt_len_32k (Prompt Length)，单条数据输入的最大长度，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "max_length_16k", "type": "int", "checkType": "range", "checkValue": [1024, 4096], "default": 2048, "name": "max_length_16k", "description": "max_length_16k (response Length)，单条数据输出的最大长度，单位为token。max_length调大会增加生成时间，并且增加显存占用。max_length+max_prompt_len应当小于序列长度。"}, {"key": "max_length_32k", "type": "int", "checkType": "range", "checkValue": [1024, 4096], "default": 2048, "name": "max_length_32k", "description": "max_length_32k (response Length)，单条数据输出的最大长度，单位为token。max_length调大会增加生成时间，并且增加显存占用。max_length+max_prompt_len应当小于序列长度。"}, {"key": "clip_range_score", "type": "int", "checkType": "range", "checkValue": [5, 50], "default": 10, "name": "clip_range_score", "description": "clip_range_score（Reward Clip），奖励分数裁剪阈值，用于限制actor和critic模型更新步幅，以保证模型更新的稳定性。调整该参数可以平衡模型更新的激进程度和训练稳定性。"}, {"key": "clip_range_value", "type": "int", "checkType": "range", "checkValue": [5, 50], "default": 5, "name": "clip_range_value", "description": "clip_range_value（PPO Critic Clip），用于限制critic模型预测新旧价值差值的裁剪阈值，以保证critic模型更新的稳定性。调整该参数可以平衡critic模型更新的激进程度和训练稳定性。"}, {"key": "clip_range_ratio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.3], "default": 0.2, "name": "clip_range_ratio", "description": "clip_range_ratio（PPO Actor Clip），用于控制actor模型更新的幅度，新旧策略的比值被裁剪到(1-clip_range_ratio,1+clip_range_ratio)范围。调整该参数可以平衡actor模型更新的激进程度和训练稳定性。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "top_p", "type": "float", "checkType": "range", "checkValue": [0, 1], "default": 0.9, "name": "top_p", "description": "top_p（Top P），用于控制模型生成文本时的创造性和随机性。调整 Top P 参数可以平衡文本的创新性和相关性。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数；为0时不开启验证，没有相关指标。"}, {"key": "repetition_penalty", "type": "float", "checkType": "range", "checkValue": [1, 2], "default": 1, "name": "repetition_penalty", "description": "repetition_penalty（Repetition Penalty），用于减少语言模型在文本生成过程中对已出现词汇的重复使用，以提高文本的多样性和连贯性。微调该参数可以平衡文本的流畅性和创新性。"}, {"key": "temperature", "type": "float", "checkType": "range", "checkValue": [0, 1], "default": 1, "name": "temperature", "description": "temperature（Temperature），用于调整语言模型输出概率分布的熵，影响生成文本的随机性和确定性。调整该参数可以平衡生成结果的确定性和多样性。"}, {"key": "kl_coeff", "type": "float", "checkType": "range", "checkValue": [0.001, 0.1], "default": 0.02, "name": "kl_coeff", "description": "kl_coeff（KL Coefficient），对reward增加增加KL-Penalty的系数。增大KL系数会使模型更紧密地逼近目标分布，减小生成文本的多样性；减小KL系数则允许模型生成更加多样化的文本，但可能偏离目标分布。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "choice", "checkValue": [64, 128, 256, 512, 1024, 2048, 4096], "default": 256, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}], "supportIdleResource": false}]}]}, {"baseModel": "ERNIE Lite", "model": "ERNIE-Lite-128K-0419", "modelType": "Text2Text", "supportTrainMode": [{"trainMode": "SFT", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 3e-05, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [16384, 32768, 65536, 131072], "default": 32768, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "pseudoSamplingProb", "type": "float", "checkType": "range", "checkValue": [0, 0.9], "default": 0, "name": "伪多轮概率", "description": "伪多轮概率（Pseudo Multi-Round Probability），随机采用数据拼接的数据增强策略的概率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 4, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 2, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage2", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 1, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}, {"trainMode": "DPO", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [16384, 32768, 65536, 131072], "default": 32768, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "dpoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "lossType", "type": "string", "checkType": "choice", "checkValue": ["sigmoid", "ipo", "kto_pair"], "default": "sigmoid", "name": "DPO偏好损失类型", "description": "DPO中偏好损失类型（Loss Type)，可选择的类型包括sigmoid、ipo、kto_pair。sigmoid适用于一般情况，提供稳定训练过程，ipo可以纠正模型过度自信的问题，kto可以使模型更符合用户偏好。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 8, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 1, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage2", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 1, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}, {"trainMode": "KTO", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [16384, 32768, 65536, 131072], "default": 32768, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "ktoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 8, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 1, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage2", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 1, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [16384, 32768, 65536, 131072], "default": 32768, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "ktoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [2, 4, 8], "default": 8, "name": "LoRA 策略中的秩", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 4, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 1, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage2", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 1, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}]}, {"baseModel": "ERNIE Lite", "model": "ERNIE-Lite-128K-0722", "modelType": "Text2Text", "supportTrainMode": [{"trainMode": "SFT", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 3e-05, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [16384, 32768, 65536, 131072], "default": 32768, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "pseudoSamplingProb", "type": "float", "checkType": "range", "checkValue": [0, 0.9], "default": 0, "name": "伪多轮概率", "description": "伪多轮概率（Pseudo Multi-Round Probability），随机采用数据拼接的数据增强策略的概率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 4, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 2, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage2", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 1, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-06, 0.001], "default": 0.0003, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [16384, 32768, 65536, 131072], "default": 32768, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [2, 4, 8], "default": 8, "name": "LoRA 策略中的秩", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "loraAllLinear", "type": "string", "checkType": "choice", "checkValue": ["True", "False"], "default": "True", "name": "LoRA所有线性层", "description": "LoRA所有线性层（LoRA in Linear）,是否将 LoRA 策略应用在所有Linear层。如果资源充足且目标是最大程度地提升模型性能，可以尝试在所有线性层上应用 LoRA，但需注意监控过拟合风险。"}, {"key": "pseudoSamplingProb", "type": "float", "checkType": "range", "checkValue": [0, 0.9], "default": 0, "name": "伪多轮概率", "description": "伪多轮概率（Pseudo Multi-Round Probability），随机采用数据拼接的数据增强策略的概率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 4, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 1, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage2", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 1, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}, {"trainMode": "DPO", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [16384, 32768, 65536, 131072], "default": 32768, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "dpoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "lossType", "type": "string", "checkType": "choice", "checkValue": ["sigmoid", "ipo", "kto_pair"], "default": "sigmoid", "name": "DPO偏好损失类型", "description": "DPO中偏好损失类型（Loss Type)，可选择的类型包括sigmoid、ipo、kto_pair。sigmoid适用于一般情况，提供稳定训练过程，ipo可以纠正模型过度自信的问题，kto可以使模型更符合用户偏好。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 8, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 1, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage2", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 1, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}, {"trainMode": "SimPO", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 3e-05, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [16384, 32768, 65536, 131072], "default": 32768, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "simpoBeta", "type": "float", "checkType": "range", "checkValue": [2, 2.5], "default": 2, "name": "温度超参", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "simpoGamma", "type": "float", "checkType": "range", "checkValue": [0.01, 1.5], "default": 0.5, "name": "边距超参", "description": "边距超参(Gamma)，SimPO目标奖励边距超参数。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 4, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 2, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage2", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 1, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}, {"trainMode": "PostPretrain", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 3e-05, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [8192, 16384, 32768, 65536, 131072], "default": 32768, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度。超过该长度的数据在训练将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 4, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 2, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage2", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 1, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": false}]}]}, {"baseModel": "ERNIE Character", "model": "ERNIE-Character-8K-0321", "modelType": "Text2Text", "supportTrainMode": [{"trainMode": "SFT", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 3e-05, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "pseudoSamplingProb", "type": "float", "checkType": "range", "checkValue": [0, 0.9], "default": 0, "name": "伪多轮概率", "description": "伪多轮概率（Pseudo Multi-Round Probability），随机采用数据拼接的数据增强策略的概率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 8, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 1, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-06, 0.001], "default": 0.0003, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [2, 4, 8], "default": 8, "name": "LoRA 策略中的秩", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "loraAllLinear", "type": "string", "checkType": "choice", "checkValue": ["True", "False"], "default": "True", "name": "LoRA所有线性层", "description": "LoRA所有线性层（LoRA in Linear）,是否将 LoRA 策略应用在所有Linear层。如果资源充足且目标是最大程度地提升模型性能，可以尝试在所有线性层上应用 LoRA，但需注意监控过拟合风险。"}, {"key": "pseudoSamplingProb", "type": "float", "checkType": "range", "checkValue": [0, 0.9], "default": 0, "name": "伪多轮概率", "description": "伪多轮概率（Pseudo Multi-Round Probability），随机采用数据拼接的数据增强策略的概率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 4, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 2, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}, {"trainMode": "KTO", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "ktoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 8, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 1, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "ktoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [2, 4, 8], "default": 8, "name": "LoRA 策略中的秩", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 4, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 2, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}]}, {"baseModel": "ERNIE Character", "model": "ERNIE-Character-Fiction-8K", "modelType": "Text2Text", "supportTrainMode": [{"trainMode": "SFT", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 3e-05, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "pseudoSamplingProb", "type": "float", "checkType": "range", "checkValue": [0, 0.9], "default": 0, "name": "伪多轮概率", "description": "伪多轮概率（Pseudo Multi-Round Probability），随机采用数据拼接的数据增强策略的概率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 8, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 1, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-06, 0.001], "default": 0.0003, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [2, 4, 8], "default": 8, "name": "LoRA 策略中的秩", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "loraAllLinear", "type": "string", "checkType": "choice", "checkValue": ["True", "False"], "default": "True", "name": "LoRA所有线性层", "description": "LoRA所有线性层（LoRA in Linear）,是否将 LoRA 策略应用在所有Linear层。如果资源充足且目标是最大程度地提升模型性能，可以尝试在所有线性层上应用 LoRA，但需注意监控过拟合风险。"}, {"key": "pseudoSamplingProb", "type": "float", "checkType": "range", "checkValue": [0, 0.9], "default": 0, "name": "伪多轮概率", "description": "伪多轮概率（Pseudo Multi-Round Probability），随机采用数据拼接的数据增强策略的概率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 4, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 2, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}, {"trainMode": "KTO", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "ktoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 8, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 1, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "ktoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [2, 4, 8], "default": 8, "name": "LoRA 策略中的秩", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 4, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 2, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}, {"trainMode": "DPO", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "dpoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "lossType", "type": "string", "checkType": "choice", "checkValue": ["sigmoid", "ipo", "kto_pair"], "default": "sigmoid", "name": "DPO偏好损失类型", "description": "DPO中偏好损失类型（Loss Type)，可选择的类型包括sigmoid、ipo、kto_pair。sigmoid适用于一般情况，提供稳定训练过程，ipo可以纠正模型过度自信的问题，kto可以使模型更符合用户偏好。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 8, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 1, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}, {"trainMode": "PostPretrain", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 3e-05, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 32, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 8, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 1, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": false}]}]}, {"baseModel": "ERNIE Character", "model": "ERNIE-Character-Fiction-8K-1028", "modelType": "Text2Text", "supportTrainMode": [{"trainMode": "SFT", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 3e-05, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "pseudoSamplingProb", "type": "float", "checkType": "range", "checkValue": [0, 0.9], "default": 0, "name": "伪多轮概率", "description": "伪多轮概率（Pseudo Multi-Round Probability），随机采用数据拼接的数据增强策略的概率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 8, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 1, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-06, 0.001], "default": 0.0003, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [2, 4, 8], "default": 8, "name": "LoRA 策略中的秩", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "loraAllLinear", "type": "string", "checkType": "choice", "checkValue": ["True", "False"], "default": "True", "name": "LoRA所有线性层", "description": "LoRA所有线性层（LoRA in Linear）,是否将 LoRA 策略应用在所有Linear层。如果资源充足且目标是最大程度地提升模型性能，可以尝试在所有线性层上应用 LoRA，但需注意监控过拟合风险。"}, {"key": "pseudoSamplingProb", "type": "float", "checkType": "range", "checkValue": [0, 0.9], "default": 0, "name": "伪多轮概率", "description": "伪多轮概率（Pseudo Multi-Round Probability），随机采用数据拼接的数据增强策略的概率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 4, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 2, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}, {"trainMode": "SimPO", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "simpoBeta", "type": "float", "checkType": "range", "checkValue": [2, 2.5], "default": 2, "name": "温度超参", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "simpoGamma", "type": "float", "checkType": "range", "checkValue": [0.01, 1.5], "default": 0.5, "name": "边距超参", "description": "边距超参(Gamma)，SimPO目标奖励边距超参数。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数；为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 8, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 1, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "simpoBeta", "type": "float", "checkType": "range", "checkValue": [2, 2.5], "default": 2, "name": "温度超参", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "simpoGamma", "type": "float", "checkType": "range", "checkValue": [0.01, 1.5], "default": 0.5, "name": "边距超参", "description": "边距超参(Gamma)，SimPO目标奖励边距超参数。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数；为0时不开启验证，没有相关指标。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [2, 4, 8], "default": 8, "name": "LoRA 策略中的秩", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}], "supportIdleResource": true}]}]}, {"baseModel": "ERNIE Tiny", "model": "ERNIE-Tiny-8K", "modelType": "Text2Text", "supportTrainMode": [{"trainMode": "SFT", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 3e-05, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 32, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "pseudoSamplingProb", "type": "float", "checkType": "range", "checkValue": [0, 0.9], "default": 0, "name": "伪多轮概率", "description": "伪多轮概率（Pseudo Multi-Round Probability），随机采用数据拼接的数据增强策略的概率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 8, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-06, 0.001], "default": 0.0003, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 32, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [2, 4, 8], "default": 8, "name": "LoRA 策略中的秩", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "loraAllLinear", "type": "string", "checkType": "choice", "checkValue": ["True", "False"], "default": "True", "name": "LoRA所有线性层", "description": "LoRA所有线性层（LoRA in Linear）,是否将 LoRA 策略应用在所有Linear层。如果资源充足且目标是最大程度地提升模型性能，可以尝试在所有线性层上应用 LoRA，但需注意监控过拟合风险。"}, {"key": "pseudoSamplingProb", "type": "float", "checkType": "range", "checkValue": [0, 0.9], "default": 0, "name": "伪多轮概率", "description": "伪多轮概率（Pseudo Multi-Round Probability），随机采用数据拼接的数据增强策略的概率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 1, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 2, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}, {"trainMode": "PostPretrain", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 3e-05, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度。超过该长度的数据在训练将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 32, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 8, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": false}]}, {"trainMode": "DPO", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 32, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "dpoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "lossType", "type": "string", "checkType": "choice", "checkValue": ["sigmoid", "ipo", "kto_pair"], "default": "sigmoid", "name": "DPO偏好损失类型", "description": "DPO中偏好损失类型（Loss Type)，可选择的类型包括sigmoid、ipo、kto_pair。sigmoid适用于一般情况，提供稳定训练过程，ipo可以纠正模型过度自信的问题，kto可以使模型更符合用户偏好。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 8, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 32, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "dpoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [2, 4, 8], "default": 8, "name": "LoRA 策略中的秩", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "lossType", "type": "string", "checkType": "choice", "checkValue": ["sigmoid", "ipo", "kto_pair"], "default": "sigmoid", "name": "DPO偏好损失类型", "description": "DPO中偏好损失类型（Loss Type)，可选择的类型包括sigmoid、ipo、kto_pair。sigmoid适用于一般情况，提供稳定训练过程，ipo可以纠正模型过度自信的问题，kto可以使模型更符合用户偏好。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 1, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 2, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}, {"trainMode": "KTO", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 32, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "ktoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 8, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 32, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "ktoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [2, 4, 8], "default": 8, "name": "LoRA 策略中的秩", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 1, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 2, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}, {"trainMode": "SimPO", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "simpoBeta", "type": "float", "checkType": "range", "checkValue": [2, 2.5], "default": 2, "name": "温度超参", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "simpoGamma", "type": "float", "checkType": "range", "checkValue": [0.01, 1.5], "default": 0.5, "name": "边距超参", "description": "边距超参(Gamma)，SimPO目标奖励边距超参数。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数；为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 8, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}]}, {"baseModel": "ERNIE Tiny", "model": "ERNIE-Tiny-128K-0929", "modelType": "Text2Text", "supportTrainMode": [{"trainMode": "SFT", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 3e-05, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [16384, 32768, 65536, 131072], "default": 32768, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "pseudoSamplingProb", "type": "float", "checkType": "range", "checkValue": [0, 0.9], "default": 0, "name": "伪多轮概率", "description": "伪多轮概率（Pseudo Multi-Round Probability），随机采用数据拼接的数据增强策略的概率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 8, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage2", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 1, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-06, 0.001], "default": 0.0003, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [16384, 32768, 65536, 131072], "default": 32768, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [2, 4, 8], "default": 8, "name": "LoRA 策略中的秩", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "loraAllLinear", "type": "string", "checkType": "choice", "checkValue": ["True", "False"], "default": "True", "name": "LoRA所有线性层", "description": "LoRA所有线性层（LoRA in Linear）,是否将 LoRA 策略应用在所有Linear层。如果资源充足且目标是最大程度地提升模型性能，可以尝试在所有线性层上应用 LoRA，但需注意监控过拟合风险。"}, {"key": "pseudoSamplingProb", "type": "float", "checkType": "range", "checkValue": [0, 0.9], "default": 0, "name": "伪多轮概率", "description": "伪多轮概率（Pseudo Multi-Round Probability），随机采用数据拼接的数据增强策略的概率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 8, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage2", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 1, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}, {"trainMode": "DPO", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [16384, 32768, 65536, 131072], "default": 32768, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "dpoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "lossType", "type": "string", "checkType": "choice", "checkValue": ["sigmoid", "ipo", "kto_pair"], "default": "sigmoid", "name": "DPO偏好损失类型", "description": "DPO中偏好损失类型（Loss Type)，可选择的类型包括sigmoid、ipo、kto_pair。sigmoid适用于一般情况，提供稳定训练过程，ipo可以纠正模型过度自信的问题，kto可以使模型更符合用户偏好。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 8, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 1, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [16384, 32768, 65536, 131072], "default": 32768, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "dpoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [2, 4, 8], "default": 8, "name": "LoRA 策略中的秩", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "lossType", "type": "string", "checkType": "choice", "checkValue": ["sigmoid", "ipo", "kto_pair"], "default": "sigmoid", "name": "DPO偏好损失类型", "description": "DPO中偏好损失类型（Loss Type)，可选择的类型包括sigmoid、ipo、kto_pair。sigmoid适用于一般情况，提供稳定训练过程，ipo可以纠正模型过度自信的问题，kto可以使模型更符合用户偏好。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 8, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage2", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 1, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}, {"trainMode": "KTO", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [16384, 32768, 65536, 131072], "default": 32768, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "ktoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 8, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 1, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [16384, 32768, 65536, 131072], "default": 32768, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "ktoBeta", "type": "float", "checkType": "range", "checkValue": [0.01, 1], "default": 0.1, "name": "beta", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [2, 4, 8], "default": 8, "name": "LoRA 策略中的秩", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 8, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage2", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 1, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}, {"trainMode": "PostPretrain", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 3e-05, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [16384, 32768, 65536, 131072], "default": 32768, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度。超过该长度的数据在训练将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 8, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage2", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 1, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": false}]}, {"trainMode": "SimPO", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 3e-05, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [16384, 32768, 65536, 131072], "default": 32768, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 16, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "simpoBeta", "type": "float", "checkType": "range", "checkValue": [2, 2.5], "default": 2, "name": "温度超参", "description": "温度超参（Beta），温度超参beta用于控制模型输出分布的集中程度。较高的beta值会使输出更具确定性，而较低的beta值则使输出更具多样性。"}, {"key": "simpoGamma", "type": "float", "checkType": "range", "checkValue": [0.01, 1.5], "default": 0.5, "name": "边距超参", "description": "边距超参(Gamma)，SimPO目标奖励边距超参数。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 8, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage2", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 1, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}]}, {"baseModel": "ERNIE 3.5", "model": "ERNIE-3.5-8K", "modelType": "Text2Text", "supportTrainMode": [{"trainMode": "SFT", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.01], "default": 3e-05, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 64, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "pseudoSamplingProb", "type": "float", "checkType": "range", "checkValue": [0, 0.9], "default": 0, "name": "伪多轮概率", "description": "伪多轮概率（Pseudo Multi-Round Probability），随机采用数据拼接的数据增强策略的概率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "linear", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 8, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 4, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 1, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 1, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.001], "default": 0.0003, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 64, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [2, 4, 8, 16, 32, 64], "default": 64, "name": "LoRA 策略中的秩", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "loraAllLinear", "type": "string", "checkType": "choice", "checkValue": ["True", "False"], "default": "True", "name": "LoRA所有线性层", "description": "LoRA所有线性层（LoRA in Linear）,是否将 LoRA 策略应用在所有Linear层。如果资源充足且目标是最大程度地提升模型性能，可以尝试在所有线性层上应用 LoRA，但需注意监控过拟合风险。"}, {"key": "pseudoSamplingProb", "type": "float", "checkType": "range", "checkValue": [0, 0.9], "default": 0, "name": "伪多轮概率", "description": "伪多轮概率（Pseudo Multi-Round Probability），随机采用数据拼接的数据增强策略的概率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "constant", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 8, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 1, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 0, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}]}, {"baseModel": "Llama", "model": "Meta-Llama-3.1-8B", "modelType": "Text2Text", "supportTrainMode": [{"trainMode": "SFT", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-10, 0.0002], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "batchSize", "type": "int", "checkType": "range", "checkValue": [1, 4], "default": 1, "name": "批处理大小", "description": "批处理大小（Batch Size），表示每次训练迭代中在每个设备上处理的样本数。较大的批处理大小可以加速训练，但可能会导致内存问题。"}, {"key": "Packing", "type": "string", "checkType": "choice", "checkValue": ["false", "true", "auto"], "default": "auto", "name": "Packing", "description": "数据拼接(Packing)，将多条训练样本拼接到一个seqLen长度内。"}, {"key": "schedulerName", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "cosine", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.1], "default": 0.03, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.001, 1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练将被自动截断，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [64, 4096], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}], "supportIdleResource": false}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-10, 0.0002], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "batchSize", "type": "int", "checkType": "range", "checkValue": [1, 4], "default": 1, "name": "批处理大小", "description": "批处理大小（Batch Size），表示每次训练迭代中在每个设备上处理的样本数。较大的批处理大小可以加速训练，但可能会导致内存问题。"}, {"key": "Packing", "type": "string", "checkType": "choice", "checkValue": ["false", "true", "auto"], "default": "auto", "name": "Packing", "description": "数据拼接(Packing)，将多条训练样本拼接到一个seqLen长度内。"}, {"key": "schedulerName", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "cosine", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.1], "default": 0.03, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.001, 1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [8, 16, 32, 64], "default": 32, "name": "loraRank", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "loraAlpha", "type": "int", "checkType": "choice", "checkValue": [8, 16, 32, 64], "default": 32, "name": "loraAlpha", "description": "LoRA微调中的缩放系数(LoRA Alpha)，定义了LoRA适应的学习率缩放因子。该参数过高，可能会导致模型的微调过度，失去原始模型的能力；改参数过低，可能达不到预期的微调效果。"}, {"key": "loraDropout", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "loraDropout", "description": "LoRA微调中的Dropout系数(LoRA Dropout)，用于防止lora训练中的过拟合。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练将被自动截断，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [64, 4096], "default": 256, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}], "supportIdleResource": false}]}]}, {"baseModel": "Llama", "model": "Meta-Llama-3.2-1B-128K", "modelType": "Text2Text", "supportTrainMode": [{"trainMode": "SFT", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-10, 0.0002], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "Packing", "type": "string", "checkType": "choice", "checkValue": ["false", "true", "auto"], "default": "auto", "name": "Packing", "description": "数据拼接(Packing)，将多条训练样本拼接到一个seqLen长度内。"}, {"key": "schedulerName", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "cosine", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.1], "default": 0.03, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.001, 1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [8192, 16384, 32768, 65536, 131072], "default": 8192, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练将被自动截断，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "batchSize128k", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "批处理大小", "description": "批处理大小（Batch Size），表示每次训练迭代中在每个设备上处理的样本数。较大的批处理大小可以加速训练，但可能会导致内存问题。"}, {"key": "batchSize64k", "type": "int", "checkType": "range", "checkValue": [1, 2], "default": 1, "name": "批处理大小", "description": "批处理大小（Batch Size），表示每次训练迭代中在每个设备上处理的样本数。较大的批处理大小可以加速训练，但可能会导致内存问题。"}, {"key": "batchSize32k", "type": "int", "checkType": "range", "checkValue": [1, 4], "default": 1, "name": "批处理大小", "description": "批处理大小（Batch Size），表示每次训练迭代中在每个设备上处理的样本数。较大的批处理大小可以加速训练，但可能会导致内存问题。"}, {"key": "batchSize16k", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "批处理大小", "description": "批处理大小（Batch Size），表示每次训练迭代中在每个设备上处理的样本数。较大的批处理大小可以加速训练，但可能会导致内存问题。"}, {"key": "batchSize8k", "type": "int", "checkType": "range", "checkValue": [1, 16], "default": 1, "name": "批处理大小", "description": "批处理大小（Batch Size），表示每次训练迭代中在每个设备上处理的样本数。较大的批处理大小可以加速训练，但可能会导致内存问题。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [64, 4096], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}], "supportIdleResource": true}]}]}, {"baseModel": "Llama", "model": "Meta-Llama-3-8B", "modelType": "Text2Text", "supportTrainMode": [{"trainMode": "SFT", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-10, 0.0002], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "batchSize", "type": "int", "checkType": "range", "checkValue": [1, 2], "default": 1, "name": "批处理大小", "description": "批处理大小（BatchSize）表示每次训练迭代中在每个设备上处理的样本数。较大的批处理大小可以加速训练，但可能会导致内存问题。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}], "supportIdleResource": false}]}]}, {"baseModel": "Llama", "model": "Qianfan-Chinese-Llama-2-1.3B", "modelType": "Text2Text", "supportTrainMode": [{"trainMode": "SFT", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-10, 0.0002], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "batchSize", "type": "int", "checkType": "range", "checkValue": [1, 4], "default": 1, "name": "批处理大小", "description": "批处理大小（Batch Size），表示每次训练迭代中在每个设备上处理的样本数。较大的批处理大小可以加速训练，但可能会导致内存问题。"}, {"key": "Packing", "type": "string", "checkType": "choice", "checkValue": ["false", "true", "auto"], "default": "auto", "name": "Packing", "description": "数据拼接(Packing)，将多条训练样本拼接到一个seqLen长度内。"}, {"key": "schedulerName", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "cosine", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.1], "default": 0.03, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.001, 1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练将被自动截断，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [64, 4096], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}], "supportIdleResource": false}]}]}, {"baseModel": "Llama", "model": "Qianfan-Chinese-Llama-2-7B", "modelType": "Text2Text", "supportTrainMode": [{"trainMode": "SFT", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-10, 0.0002], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "batchSize", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 1, "name": "批处理大小", "description": "批处理大小（BatchSize）表示每次训练迭代中在每个设备上处理的样本数。较大的批处理大小可以加速训练，但可能会导致内存问题。"}, {"key": "Packing", "type": "string", "checkType": "choice", "checkValue": ["false", "true", "auto"], "default": "auto", "name": "Packing", "description": "数据拼接(Packing)，将多条训练样本拼接到一个seqLen长度内。"}, {"key": "schedulerName", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "cosine", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.1], "default": 0.03, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.001, 1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练将被自动截断，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [64, 4096], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}], "supportIdleResource": false}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-10, 0.0002], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "batchSize", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 1, "name": "批处理大小", "description": "批处理大小（BatchSize）表示每次训练迭代中在每个设备上处理的样本数。较大的批处理大小可以加速训练，但可能会导致内存问题。"}, {"key": "Packing", "type": "string", "checkType": "choice", "checkValue": ["false", "true", "auto"], "default": "auto", "name": "Packing", "description": "数据拼接(Packing)，将多条训练样本拼接到一个seqLen长度内。"}, {"key": "schedulerName", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "cosine", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.1], "default": 0.03, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.001, 1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [8, 16, 32, 64], "default": 32, "name": "loraRank", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "loraAlpha", "type": "int", "checkType": "choice", "checkValue": [8, 16, 32, 64], "default": 32, "name": "loraAlpha", "description": "LoRA微调中的缩放系数(LoRA Alpha)，定义了LoRA适应的学习率缩放因子。该参数过高，可能会导致模型的微调过度，失去原始模型的能力；改参数过低，可能达不到预期的微调效果。"}, {"key": "loraDropout", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "loraDropout", "description": "LoRA微调中的Dropout系数(LoRA Dropout)，用于防止lora训练中的过拟合。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练将被自动截断，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [64, 4096], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}], "supportIdleResource": false}]}]}, {"baseModel": "Llama", "model": "Qianfan-Chinese-Llama-2-7B-32K", "modelType": "Text2Text", "supportTrainMode": [{"trainMode": "SFT", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-10, 0.0002], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "batchSize", "type": "int", "checkType": "choice", "checkValue": [1], "default": 1, "name": "批处理大小", "description": "批处理大小（BatchSize）表示每次训练迭代中在每个设备上处理的样本数。较大的批处理大小可以加速训练，但可能会导致内存问题。"}, {"key": "Packing", "type": "string", "checkType": "choice", "checkValue": ["false", "true", "auto"], "default": "auto", "name": "Packing", "description": "数据拼接(Packing)，将多条训练样本拼接到一个seqLen长度内。"}, {"key": "schedulerName", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "cosine", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.1], "default": 0.03, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.001, 1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [4096, 8192, 16384, 32768], "default": 32768, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练将被自动截断，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [64, 4096], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}], "supportIdleResource": false}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-10, 0.0002], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "batchSize", "type": "int", "checkType": "choice", "checkValue": [1], "default": 1, "name": "批处理大小", "description": "批处理大小（BatchSize）表示每次训练迭代中在每个设备上处理的样本数。较大的批处理大小可以加速训练，但可能会导致内存问题。"}, {"key": "Packing", "type": "string", "checkType": "choice", "checkValue": ["false", "true", "auto"], "default": "auto", "name": "Packing", "description": "数据拼接(Packing)，将多条训练样本拼接到一个seqLen长度内。"}, {"key": "schedulerName", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "cosine", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.1], "default": 0.03, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.001, 1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [8, 16, 32, 64], "default": 32, "name": "loraRank", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "loraAlpha", "type": "int", "checkType": "choice", "checkValue": [8, 16, 32, 64], "default": 32, "name": "loraAlpha", "description": "LoRA微调中的缩放系数(LoRA Alpha)，定义了LoRA适应的学习率缩放因子。该参数过高，可能会导致模型的微调过度，失去原始模型的能力；改参数过低，可能达不到预期的微调效果。"}, {"key": "loraDropout", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "loraDropout", "description": "LoRA微调中的Dropout系数(LoRA Dropout)，用于防止lora训练中的过拟合。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [4096, 8192, 16384, 32768], "default": 32768, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练将被自动截断，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [64, 4096], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}], "supportIdleResource": false}]}]}, {"baseModel": "Llama", "model": "Qianfan-Chinese-Llama-2-13B-v1", "modelType": "Text2Text", "supportTrainMode": [{"trainMode": "SFT", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-10, 0.0002], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "batchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "批处理大小", "description": "批处理大小（BatchSize）表示每次训练迭代中在每个设备上处理的样本数。较大的批处理大小可以加速训练，但可能会导致内存问题。"}, {"key": "Packing", "type": "string", "checkType": "choice", "checkValue": ["false", "true", "auto"], "default": "auto", "name": "Packing", "description": "数据拼接(Packing)，将多条训练样本拼接到一个seqLen长度内。"}, {"key": "schedulerName", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "cosine", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.1], "default": 0.03, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.001, 1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练将被自动截断，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [64, 4096], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}], "supportIdleResource": false}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-10, 0.0002], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "batchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "批处理大小", "description": "批处理大小（BatchSize）表示每次训练迭代中在每个设备上处理的样本数。较大的批处理大小可以加速训练，但可能会导致内存问题。"}, {"key": "Packing", "type": "string", "checkType": "choice", "checkValue": ["false", "true", "auto"], "default": "auto", "name": "Packing", "description": "数据拼接(Packing)，将多条训练样本拼接到一个seqLen长度内。"}, {"key": "schedulerName", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "cosine", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.1], "default": 0.03, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.001, 1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [8, 16, 32, 64], "default": 32, "name": "loraRank", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "loraAlpha", "type": "int", "checkType": "choice", "checkValue": [8, 16, 32, 64], "default": 32, "name": "loraAlpha", "description": "LoRA微调中的缩放系数(LoRA Alpha)，定义了LoRA适应的学习率缩放因子。该参数过高，可能会导致模型的微调过度，失去原始模型的能力；改参数过低，可能达不到预期的微调效果。"}, {"key": "loraDropout", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "loraDropout", "description": "LoRA微调中的Dropout系数(LoRA Dropout)，用于防止lora训练中的过拟合。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练将被自动截断，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [64, 4096], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}], "supportIdleResource": false}]}, {"trainMode": "PostPretrain", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "batchSize", "type": "int", "checkType": "range", "checkValue": [48, 960], "default": 192, "name": "批处理大小", "description": "批处理大小（Batch Size），表示每次训练迭代中在每个设备上处理的样本数。较大的批处理大小可以加速训练，但可能会导致内存问题。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [2e-07, 0.0002], "default": 2e-05, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.05], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [64, 8192], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}], "supportIdleResource": false}]}]}, {"baseModel": "Llama", "model": "Qianfan-Chinese-Llama-2-13B-v2", "modelType": "Text2Text", "supportTrainMode": [{"trainMode": "SFT", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-10, 0.0002], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "batchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "批处理大小", "description": "批处理大小（BatchSize）表示每次训练迭代中在每个设备上处理的样本数。较大的批处理大小可以加速训练，但可能会导致内存问题。"}, {"key": "Packing", "type": "string", "checkType": "choice", "checkValue": ["false", "true", "auto"], "default": "auto", "name": "Packing", "description": "数据拼接(Packing)，将多条训练样本拼接到一个seqLen长度内。"}, {"key": "schedulerName", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "cosine", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.1], "default": 0.03, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.001, 1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练将被自动截断，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [64, 4096], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}], "supportIdleResource": false}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-10, 0.0002], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "batchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "批处理大小", "description": "批处理大小（BatchSize）表示每次训练迭代中在每个设备上处理的样本数。较大的批处理大小可以加速训练，但可能会导致内存问题。"}, {"key": "Packing", "type": "string", "checkType": "choice", "checkValue": ["false", "true", "auto"], "default": "auto", "name": "Packing", "description": "数据拼接(Packing)，将多条训练样本拼接到一个seqLen长度内。"}, {"key": "schedulerName", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "cosine", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.1], "default": 0.03, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.001, 1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [8, 16, 32, 64], "default": 32, "name": "loraRank", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "loraAlpha", "type": "int", "checkType": "choice", "checkValue": [8, 16, 32, 64], "default": 32, "name": "loraAlpha", "description": "LoRA微调中的缩放系数(LoRA Alpha)，定义了LoRA适应的学习率缩放因子。该参数过高，可能会导致模型的微调过度，失去原始模型的能力；改参数过低，可能达不到预期的微调效果。"}, {"key": "loraDropout", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "loraDropout", "description": "LoRA微调中的Dropout系数(LoRA Dropout)，用于防止lora训练中的过拟合。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练将被自动截断，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [64, 4096], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}], "supportIdleResource": false}]}]}, {"baseModel": "ERNIE 4.0 Turbo", "model": "ERNIE-4.0-Turbo-8K", "modelType": "Text2Text", "supportTrainMode": [{"trainMode": "SFT", "supportParameterScale": [{"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-07, 0.001], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练时将被舍弃，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "globalBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 10000], "default": 18, "name": "全局批大小", "description": "全局批大小（Global Batch Size），每次训练迭代使用的样本数，为了加快训练效率，多条样本会使用Packing尽可能拼接到一个序列长度内。"}, {"key": "loggingSteps", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "保存日志间隔", "description": "保存日志间隔（Logging Interval），设定模型训练过程中记录日志的间隔步数。合理设置可以平衡日志记录的详细程度和存储、处理资源的消耗。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.0001, 0.1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [2, 4, 8, 16, 32, 64], "default": 64, "name": "LoRA 策略中的秩", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "loraAllLinear", "type": "string", "checkType": "choice", "checkValue": ["True", "False"], "default": "True", "name": "LoRA所有线性层", "description": "LoRA所有线性层（LoRA in Linear）,是否将 LoRA 策略应用在所有Linear层。如果资源充足且目标是最大程度地提升模型性能，可以尝试在所有线性层上应用 LoRA，但需注意监控过拟合风险。"}, {"key": "pseudoSamplingProb", "type": "float", "checkType": "range", "checkValue": [0, 0.9], "default": 0, "name": "伪多轮概率", "description": "伪多轮概率（Pseudo Multi-Round Probability），随机采用数据拼接的数据增强策略的概率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "seed", "type": "int", "checkType": "range", "checkValue": [1, 2147483647], "default": 42, "name": "随机种子", "description": "随机种子（Random Seed），是在随机数生成算法中设定的一个初始值，用于确保随机数生成的可重复性。通过设置随机种子，可以在相同的算法和参数下，生成相同的随机数序列。"}, {"key": "lrSchedulerType", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "constant", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "numCycles", "type": "float", "checkType": "range", "checkValue": [0.1, 0.5], "default": 0.5, "name": "cosine 策略的波数", "description": "cosine 策略的波数（Period of Cosine），波数定义了余弦函数周期的长短。减少波数可以使模型训练过程稳定，增加波数可以避免陷入局部最优。"}, {"key": "lrEnd", "type": "float", "checkType": "range", "checkValue": [1e-08, 1e-06], "default": 1e-07, "name": "polynomial 策略的末端 LR", "description": "polynomial 策略的末端 LR（Polynomial Decay End Learning Rate），指的是在多项式衰减策略中，学习率下降到最后所达到的最小值。这个值通常设置得较低，该值若生效需要比学习率小，保证在模型训练后期实现细致的优化。"}, {"key": "power", "type": "int", "checkType": "range", "checkValue": [1, 3], "default": 1, "name": "polynomial 策略的幂数", "description": "polynomial 策略的幂数（Polynomial Decay Power），是指在多项式衰减学习率调整策略中，用于控制学习率下降曲线陡峭程度的指数。幂数越大，可以避免陷入局部最优；幂数越小，可以使模型训练过程稳定。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "earlyStopping", "type": "string", "checkType": "choice", "checkValue": ["False", "True"], "default": "False", "name": "早停策略", "description": "早停策略（Early Stopping），监控精调任务的指标变化情况，指标连续不变则提前终止训练。"}, {"key": "earlyStopMetric", "type": "string", "checkType": "choice", "checkValue": ["validationLoss"], "default": "validationLoss", "name": "早停指标", "description": "早停指标（Early Stopping Metric），根据该监控指标决定任务是否早停。"}, {"key": "earlyStoppingThreshold", "type": "float", "checkType": "range", "checkValue": [0, 5], "default": 0.01, "name": "早停指标变化量", "description": "早停指标变化量（Early Stopping Metric Change），当精调任务指标的变化量超过早停指标变化量时才认为发生变化。根据实际损失曲线进行决定。"}, {"key": "earlyStoppingPatience", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "早停指标稳定次数", "description": "早停指标稳定次数（Early Stopping Patience），早停指标连续不变化的次数。如果设置的稳定次数较小，早停策略会更敏感，可能在模型尚未充分训练时就停止训练；如果设置的稳定次数较大，早停策略会更宽松，允许模型有更多的训练周期来改善性能。"}, {"key": "tensorParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 8, "name": "模型并行", "description": "模型并行(Model Parallelism，MP)，对模型参数进行切分，能够有效减少参数显存占用，但通信量比较高，适合在机器内做模型并行。"}, {"key": "pipelineParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "流水线并行", "description": "流水线并行（Pipeline Parallelism，PP）将模型的不同层放置到不同的计算设备，降低单个计算设备的显存消耗，从而实现超大规模模型训练。但加速效率没有DP高，适合在机器间使用。"}, {"key": "shardingParallelDegree", "type": "int", "checkType": "range", "checkValue": [1, 64], "default": 1, "name": "分组参数切片并行", "description": "分组参数切片并行（Sharding Parallel，SDP），兼容了MP+DP的优势，缺点为通信量大。"}, {"key": "sharding", "type": "string", "checkType": "choice", "checkValue": ["stage1", "stage2", "stage3"], "default": "stage1", "name": "分组参数策略", "description": "分组参数策略（Sharding）作用的Stage，stage1 代表优化器参数分片，stage2 表示梯度分片，stage3 表示模型参数分片。"}, {"key": "recompute", "type": "int", "checkType": "choice", "checkValue": [0, 1], "default": 1, "name": "重计算", "description": "重计算(Recompute)在反向时重新计算前向结果，能够有效减少中间显存占用，但性能损耗较多。默认0为不重计算。"}, {"key": "perDeviceTrainBatchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 1, "name": "微批大小", "description": "微批大小（Micro BatchSize）用于在单个计算节点中进一步划分数据。"}], "supportIdleResource": true}]}]}, {"baseModel": "Mixtral-8x7B", "model": "Mixtral-8x7B", "modelType": "Text2Text", "supportTrainMode": [{"trainMode": "SFT", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 20], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-10, 0.0002], "default": 1e-05, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "batchSize", "type": "int", "checkType": "range", "checkValue": [1, 4], "default": 1, "name": "批处理大小", "description": "批处理大小（Batch Size），表示每次训练迭代中在每个设备上处理的样本数。较大的批处理大小可以加速训练，但可能会导致内存问题。"}, {"key": "Packing", "type": "string", "checkType": "choice", "checkValue": ["false", "true", "auto"], "default": "auto", "name": "Packing", "description": "数据拼接(Packing)，将多条训练样本拼接到一个seqLen长度内。"}, {"key": "schedulerName", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "cosine", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.1], "default": 0.03, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.001, 1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练将被自动截断，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [64, 4096], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}], "supportIdleResource": false}]}]}, {"baseModel": "SQLCoder-7B", "model": "SQLCoder-7B", "modelType": "Text2Text", "supportTrainMode": [{"trainMode": "SFT", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-10, 0.0002], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "batchSize", "type": "int", "checkType": "range", "checkValue": [1, 4], "default": 1, "name": "批处理大小", "description": "批处理大小（Batch Size），表示每次训练迭代中在每个设备上处理的样本数。较大的批处理大小可以加速训练，但可能会导致内存问题。"}, {"key": "Packing", "type": "string", "checkType": "choice", "checkValue": ["false", "true", "auto"], "default": "auto", "name": "Packing", "description": "数据拼接(Packing)，将多条训练样本拼接到一个seqLen长度内。"}, {"key": "schedulerName", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "cosine", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.1], "default": 0.03, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.001, 1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练将被自动截断，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [64, 4096], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}], "supportIdleResource": false}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-10, 0.0002], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "batchSize", "type": "int", "checkType": "range", "checkValue": [1, 4], "default": 1, "name": "批处理大小", "description": "批处理大小（Batch Size），表示每次训练迭代中在每个设备上处理的样本数。较大的批处理大小可以加速训练，但可能会导致内存问题。"}, {"key": "Packing", "type": "string", "checkType": "choice", "checkValue": ["false", "true", "auto"], "default": "auto", "name": "Packing", "description": "数据拼接(Packing)，将多条训练样本拼接到一个seqLen长度内。"}, {"key": "schedulerName", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "cosine", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.1], "default": 0.03, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.001, 1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [8, 16, 32, 64], "default": 32, "name": "loraRank", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "loraAlpha", "type": "int", "checkType": "choice", "checkValue": [8, 16, 32, 64], "default": 32, "name": "loraAlpha", "description": "LoRA微调中的缩放系数(LoRA Alpha)，定义了LoRA适应的学习率缩放因子。该参数过高，可能会导致模型的微调过度，失去原始模型的能力；改参数过低，可能达不到预期的微调效果。"}, {"key": "loraDropout", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "loraDropout", "description": "LoRA微调中的Dropout系数(LoRA Dropout)，用于防止lora训练中的过拟合。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练将被自动截断，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [64, 4096], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}], "supportIdleResource": false}]}]}, {"baseModel": "ChatGLM", "model": "ChatGLM2-6B-32K", "modelType": "Text2Text", "supportTrainMode": [{"trainMode": "SFT", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [4096, 8192, 16384, 32768], "default": 32768, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练将被自动截断，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "batchSize", "type": "int", "checkType": "range", "checkValue": [1, 1], "default": 1, "name": "批处理大小", "description": "批处理大小（Batch Size），表示每次训练迭代中在每个设备上处理的样本数。较大的批处理大小可以加速训练，但可能会导致内存问题。"}, {"key": "Packing", "type": "string", "checkType": "choice", "checkValue": ["false", "true", "auto"], "default": "auto", "name": "Packing", "description": "数据拼接(Packing)，将多条训练样本拼接到一个seqLen长度内。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-10, 0.0002], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "schedulerName", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "cosine", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.1], "default": 0.03, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.001, 1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [64, 4096], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}], "supportIdleResource": false}]}]}, {"baseModel": "ChatGLM", "model": "ChatGLM2-6B", "modelType": "Text2Text", "supportTrainMode": [{"trainMode": "SFT", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-10, 0.0002], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "batchSize", "type": "int", "checkType": "range", "checkValue": [1, 2], "default": 1, "name": "批处理大小", "description": "批处理大小（BatchSize）表示每次训练迭代中在每个设备上处理的样本数。较大的批处理大小可以加速训练，但可能会导致内存问题。"}, {"key": "Packing", "type": "string", "checkType": "choice", "checkValue": ["false", "true", "auto"], "default": "auto", "name": "Packing", "description": "数据拼接(Packing)，将多条训练样本拼接到一个seqLen长度内。"}, {"key": "schedulerName", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "cosine", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.1], "default": 0.03, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.001, 1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练将被自动截断，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [64, 4096], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}], "supportIdleResource": false}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-10, 0.0002], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "batchSize", "type": "int", "checkType": "range", "checkValue": [1, 2], "default": 1, "name": "批处理大小", "description": "批处理大小（BatchSize）表示每次训练迭代中在每个设备上处理的样本数。较大的批处理大小可以加速训练，但可能会导致内存问题。"}, {"key": "Packing", "type": "string", "checkType": "choice", "checkValue": ["false", "true", "auto"], "default": "auto", "name": "Packing", "description": "数据拼接(Packing)，将多条训练样本拼接到一个seqLen长度内。"}, {"key": "schedulerName", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "cosine", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.1], "default": 0.03, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.001, 1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [8, 16, 32, 64], "default": 32, "name": "loraRank", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "loraAlpha", "type": "int", "checkType": "choice", "checkValue": [8, 16, 32, 64], "default": 32, "name": "loraAlpha", "description": "LoRA微调中的缩放系数(LoRA Alpha)，定义了LoRA适应的学习率缩放因子。该参数过高，可能会导致模型的微调过度，失去原始模型的能力；改参数过低，可能达不到预期的微调效果。"}, {"key": "loraDropout", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "loraDropout", "description": "LoRA微调中的Dropout系数(LoRA Dropout)，用于防止lora训练中的过拟合。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练将被自动截断，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [64, 4096], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}], "supportIdleResource": false}]}]}, {"baseModel": "ChatGLM", "model": "ChatGLM3-6B", "modelType": "Text2Text", "supportTrainMode": [{"trainMode": "SFT", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 3, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-10, 0.0002], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "batchSize", "type": "int", "checkType": "choice", "checkValue": [16, 32, 64], "default": 16, "name": "批处理大小", "description": "批处理大小（BatchSize）表示每次训练迭代中在每个设备上处理的样本数。较大的批处理大小可以加速训练，但可能会导致内存问题。"}, {"key": "Packing", "type": "string", "checkType": "choice", "checkValue": ["false", "true", "auto"], "default": "auto", "name": "Packing", "description": "数据拼接(Packing)，将多条训练样本拼接到一个seqLen长度内。"}, {"key": "schedulerName", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "cosine", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.1], "default": 0.03, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.001, 1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [4096, 8192], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练将被自动截断，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [64, 4096], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}], "supportIdleResource": false}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-10, 0.0002], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "batchSize", "type": "int", "checkType": "choice", "checkValue": [16, 32, 64], "default": 16, "name": "批处理大小", "description": "批处理大小（BatchSize）表示每次训练迭代中在每个设备上处理的样本数。较大的批处理大小可以加速训练，但可能会导致内存问题。"}, {"key": "Packing", "type": "string", "checkType": "choice", "checkValue": ["false", "true", "auto"], "default": "auto", "name": "Packing", "description": "数据拼接(Packing)，将多条训练样本拼接到一个seqLen长度内。"}, {"key": "schedulerName", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "cosine", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.1], "default": 0.03, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.001, 1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [8, 16, 32, 64], "default": 32, "name": "loraRank", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "loraAlpha", "type": "int", "checkType": "choice", "checkValue": [8, 16, 32, 64], "default": 32, "name": "loraAlpha", "description": "LoRA微调中的缩放系数(LoRA Alpha)，定义了LoRA适应的学习率缩放因子。该参数过高，可能会导致模型的微调过度，失去原始模型的能力；改参数过低，可能达不到预期的微调效果。"}, {"key": "loraDropout", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "loraDropout", "description": "LoRA微调中的Dropout系数(LoRA Dropout)，用于防止lora训练中的过拟合。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练将被自动截断，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [64, 4096], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}], "supportIdleResource": false}]}]}, {"baseModel": "Baichuan2", "model": "Baichuan2-7B-Chat", "modelType": "Text2Text", "supportTrainMode": [{"trainMode": "SFT", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-10, 0.0002], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "batchSize", "type": "int", "checkType": "range", "checkValue": [1, 4], "default": 1, "name": "批处理大小", "description": "批处理大小（Batch Size），表示每次训练迭代中在每个设备上处理的样本数。较大的批处理大小可以加速训练，但可能会导致内存问题。"}, {"key": "schedulerName", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "cosine", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.1], "default": 0.03, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.001, 1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练将被自动截断，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "Packing", "type": "string", "checkType": "choice", "checkValue": ["false", "true", "auto"], "default": "auto", "name": "Packing", "description": "数据拼接(Packing)，将多条训练样本拼接到一个seqLen长度内。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [64, 4096], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}], "supportIdleResource": false}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-10, 0.0002], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "batchSize", "type": "int", "checkType": "range", "checkValue": [1, 4], "default": 1, "name": "批处理大小", "description": "批处理大小（Batch Size），表示每次训练迭代中在每个设备上处理的样本数。较大的批处理大小可以加速训练，但可能会导致内存问题。"}, {"key": "schedulerName", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "cosine", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.1], "default": 0.03, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.001, 1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练将被自动截断，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "Packing", "type": "string", "checkType": "choice", "checkValue": ["false", "true", "auto"], "default": "auto", "name": "Packing", "description": "数据拼接(Packing)，将多条训练样本拼接到一个seqLen长度内。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [8, 16, 32, 64], "default": 32, "name": "loraRank", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "loraAlpha", "type": "int", "checkType": "choice", "checkValue": [8, 16, 32, 64], "default": 32, "name": "loraAlpha", "description": "LoRA微调中的缩放系数(LoRA Alpha)，定义了LoRA适应的学习率缩放因子。该参数过高，可能会导致模型的微调过度，失去原始模型的能力；改参数过低，可能达不到预期的微调效果。"}, {"key": "loraDropout", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "loraDropout", "description": "LoRA微调中的Dropout系数(LoRA Dropout)，用于防止lora训练中的过拟合。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [64, 4096], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}], "supportIdleResource": false}]}]}, {"baseModel": "Baichuan2", "model": "Baichuan2-13B-Chat", "modelType": "Text2Text", "supportTrainMode": [{"trainMode": "SFT", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-10, 0.0002], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "batchSize", "type": "int", "checkType": "range", "checkValue": [1, 2], "default": 1, "name": "批处理大小", "description": "批处理大小（Batch Size），表示每次训练迭代中在每个设备上处理的样本数。较大的批处理大小可以加速训练，但可能会导致内存问题。"}, {"key": "schedulerName", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "cosine", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.1], "default": 0.03, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.001, 1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练将被自动截断，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "Packing", "type": "string", "checkType": "choice", "checkValue": ["false", "true", "auto"], "default": "auto", "name": "Packing", "description": "数据拼接(Packing)，将多条训练样本拼接到一个seqLen长度内。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [64, 4096], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}], "supportIdleResource": false}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-10, 0.0002], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "batchSize", "type": "int", "checkType": "range", "checkValue": [1, 2], "default": 1, "name": "批处理大小", "description": "批处理大小（Batch Size），表示每次训练迭代中在每个设备上处理的样本数。较大的批处理大小可以加速训练，但可能会导致内存问题。"}, {"key": "schedulerName", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "cosine", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.1], "default": 0.03, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.001, 1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练将被自动截断，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "Packing", "type": "string", "checkType": "choice", "checkValue": ["false", "true", "auto"], "default": "auto", "name": "Packing", "description": "数据拼接(Packing)，将多条训练样本拼接到一个seqLen长度内。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [8, 16, 32, 64], "default": 32, "name": "loraRank", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "loraAlpha", "type": "int", "checkType": "choice", "checkValue": [8, 16, 32, 64], "default": 32, "name": "loraAlpha", "description": "LoRA微调中的缩放系数(LoRA Alpha)，定义了LoRA适应的学习率缩放因子。该参数过高，可能会导致模型的微调过度，失去原始模型的能力；改参数过低，可能达不到预期的微调效果。"}, {"key": "loraDropout", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "loraDropout", "description": "LoRA微调中的Dropout系数(LoRA Dropout)，用于防止lora训练中的过拟合。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [64, 4096], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}], "supportIdleResource": false}]}]}, {"baseModel": "BLOOMZ-7B", "model": "BLOOMZ-7B", "modelType": "Text2Text", "supportTrainMode": [{"trainMode": "SFT", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-10, 0.0002], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "batchSize", "type": "int", "checkType": "range", "checkValue": [1, 4], "default": 1, "name": "批处理大小", "description": "批处理大小（Batch Size），表示每次训练迭代中在每个设备上处理的样本数。较大的批处理大小可以加速训练，但可能会导致内存问题。"}, {"key": "Packing", "type": "string", "checkType": "choice", "checkValue": ["false", "true", "auto"], "default": "auto", "name": "Packing", "description": "数据拼接(Packing)，将多条训练样本拼接到一个seqLen长度内。"}, {"key": "schedulerName", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "cosine", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.1], "default": 0.03, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.001, 1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [64, 4096], "default": 256, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}], "supportIdleResource": false}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-10, 0.0002], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "batchSize", "type": "int", "checkType": "range", "checkValue": [1, 4], "default": 1, "name": "批处理大小", "description": "批处理大小（Batch Size），表示每次训练迭代中在每个设备上处理的样本数。较大的批处理大小可以加速训练，但可能会导致内存问题。"}, {"key": "Packing", "type": "string", "checkType": "choice", "checkValue": ["false", "true", "auto"], "default": "auto", "name": "Packing", "description": "数据拼接(Packing)，将多条训练样本拼接到一个seqLen长度内。"}, {"key": "schedulerName", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "cosine", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.1], "default": 0.03, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.001, 1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [8, 16, 32, 64], "default": 32, "name": "loraRank", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "loraAlpha", "type": "int", "checkType": "choice", "checkValue": [8, 16, 32, 64], "default": 32, "name": "loraAlpha", "description": "LoRA微调中的缩放系数(LoRA Alpha)，定义了LoRA适应的学习率缩放因子。该参数过高，可能会导致模型的微调过度，失去原始模型的能力；改参数过低，可能达不到预期的微调效果。"}, {"key": "loraDropout", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "loraDropout", "description": "LoRA微调中的Dropout系数(LoRA Dropout)，用于防止lora训练中的过拟合。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [64, 4096], "default": 256, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}], "supportIdleResource": false}]}]}, {"baseModel": "CodeLlama", "model": "CodeLlama-7B", "modelType": "Text2Text", "supportTrainMode": [{"trainMode": "SFT", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-10, 0.0002], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "batchSize", "type": "int", "checkType": "range", "checkValue": [1, 4], "default": 1, "name": "批处理大小", "description": "批处理大小（Batch Size），表示每次训练迭代中在每个设备上处理的样本数。较大的批处理大小可以加速训练，但可能会导致内存问题。"}, {"key": "Packing", "type": "string", "checkType": "choice", "checkValue": ["false", "true", "auto"], "default": "auto", "name": "Packing", "description": "数据拼接(Packing)，将多条训练样本拼接到一个seqLen长度内。"}, {"key": "schedulerName", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "cosine", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.1], "default": 0.03, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.001, 1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练将被自动截断，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [64, 4096], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}], "supportIdleResource": false}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-10, 0.0002], "default": 1e-06, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "batchSize", "type": "int", "checkType": "range", "checkValue": [1, 4], "default": 1, "name": "批处理大小", "description": "批处理大小（Batch Size），表示每次训练迭代中在每个设备上处理的样本数。较大的批处理大小可以加速训练，但可能会导致内存问题。"}, {"key": "Packing", "type": "string", "checkType": "choice", "checkValue": ["false", "true", "auto"], "default": "auto", "name": "Packing", "description": "数据拼接(Packing)，将多条训练样本拼接到一个seqLen长度内。"}, {"key": "schedulerName", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "cosine", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.1], "default": 0.03, "name": "预热比例", "description": "预热比例（Learning Rate Warmup），训练初期学习率预热步数占用总的训练步数的比例。学习率预热可以提高模型稳定性和收敛速度。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.001, 1], "default": 0.01, "name": "正则化系数", "description": "正则化系数（Weight Decay），控制正则化项对模型参数的影响强度。适当增大系数可以增强正则化效果，防止过拟合，但过高的系数可能导致模型欠拟合。"}, {"key": "loraTargetModules", "type": "string", "checkType": "mult_choice", "checkValue": ["self_attn.q_proj", "self_attn.k_proj", "self_attn.v_proj", "self_attn.o_proj", "mlp.gate_proj", "mlp.up_proj", "mlp.down_proj"], "default": ["self_attn.q_proj", "self_attn.v_proj"], "name": "loraTargetModules", "description": "LoRA参数层列表"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [8, 16, 32, 64], "default": 32, "name": "loraRank", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "loraAlpha", "type": "int", "checkType": "choice", "checkValue": [8, 16, 32, 64], "default": 32, "name": "loraAlpha", "description": "LoRA微调中的缩放系数(LoRA Alpha)，定义了LoRA适应的学习率缩放因子。该参数过高，可能会导致模型的微调过度，失去原始模型的能力；改参数过低，可能达不到预期的微调效果。"}, {"key": "loraDropout", "type": "float", "checkType": "range", "checkValue": [0.01, 0.5], "default": 0.1, "name": "loraDropout", "description": "LoRA微调中的Dropout系数(LoRA Dropout)，用于防止lora训练中的过拟合。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096], "default": 4096, "name": "序列长度", "description": "序列长度(Sequence Length)，单条数据的最大长度，包括输入和输出。超过该长度的数据在训练将被自动截断，单位为token。如果数据集中的文本普遍较短，建议选择较短的序列长度以提高计算效率。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Steps），计算验证集Loss的间隔步数，为0时不开启验证，没有相关指标。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [64, 4096], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}], "supportIdleResource": false}]}]}, {"baseModel": "WENXIN-YIGE", "model": "WENXIN-YIGE", "modelType": "Text2Image", "supportTrainMode": [{"trainMode": "SFT", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 100], "default": 20, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制训练过程中的迭代轮数。可以根据数据规模适当调整Epoch大小。"}, {"key": "batchSize", "type": "int", "checkType": "range", "checkValue": [1, 8], "default": 8, "name": "批处理大小", "description": "批处理大小（BatchSize）表示在每次训练迭代中使用的样本数。较大的批处理大小可以加速训练，推荐使用最大的BatchSize。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-08, 0.01], "default": 1e-05, "name": "学习率", "description": "学习率（LearningRate）是在梯度下降的过程中更新权重时的超参数，过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}], "supportIdleResource": false}]}]}, {"baseModel": "Stable-Diffusion-XL", "model": "Stable-Diffusion-XL-Base-1.0", "modelType": "Text2Image", "supportTrainMode": [{"trainMode": "SFT", "supportParameterScale": [{"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 100], "default": 20, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制训练过程中的迭代轮数。可以根据数据规模适当调整Epoch大小，建议设置在1-5之间，小数据量可以适当增大Epoch，让模型充分收敛。"}, {"key": "batchSize", "type": "int", "checkType": "range", "checkValue": [2, 8], "default": 8, "name": "批处理大小", "description": "批处理大小（BatchSize）表示在每次训练迭代中使用的样本数。较大的批处理大小可以加速训练，佉可能会导致内存问题。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-05, 0.0001], "default": 5e-05, "name": "学习率", "description": "学习率（LearningRate）是在梯度下降的过程中更新权重时的超参数，过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}], "supportIdleResource": false}]}]}, {"baseModel": "LLAVA", "model": "LLAVA-V1.6-13B", "modelType": "ImageUnderstanding", "supportTrainMode": [{"trainMode": "SFT", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制训练过程中的迭代轮数。可以根据数据规模适当调整Epoch大小，建议设置在1-5之间，小数据量可以适当增大Epoch，让模型充分收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-10, 0.001], "default": 1e-05, "name": "学习率", "description": "学习率（LearningRate）是在梯度下降的过程中更新权重时的超参数，过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "batchSize", "type": "int", "checkType": "range", "checkValue": [1, 16], "default": 1, "name": "批处理大小", "description": "批处理大小（BatchSize）表示在每次训练迭代中使用的样本数。较大的批处理大小可以加速训练，佉可能会导致内存问题。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "Validation Step，计算验证集Loss的间隔步数；为0时不开启验证，没有相关指标。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "训练过程最终要保存的Checkpoint个数，Checkpoint保存会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "训练过程中保存Checkpoint的间隔Step数。"}, {"key": "schedulerName", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "cosine", "name": "学习率调整计划", "description": "学习率调整计划（schedulerName），用于调整训练中学习率的变动方式。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.1], "default": 0.05, "name": "学习率预热步数占比", "description": "学习率预热步数占比（warmupRatio），指训练初始阶段，在学习率较低的情况下逐渐增加学习率的比例。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.001, 1], "default": 0.1, "name": "权重衰减数值", "description": "权重衰减数值（weightDecay），是一种正则化技术，用于帮助控制神经网络模型的复杂性以及减少过拟合的风险。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096], "default": 2048, "name": "序列长度", "description": "序列长度（seqLen），单条样本的最大长度。如果训练数据较短，减少此项可以加快训练速度。"}], "supportIdleResource": false}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制训练过程中的迭代轮数。可以根据数据规模适当调整Epoch大小，建议设置在1-5之间，小数据量可以适当增大Epoch，让模型充分收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-10, 0.001], "default": 0.0001, "name": "学习率", "description": "学习率（LearningRate）是在梯度下降的过程中更新权重时的超参数，过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "batchSize", "type": "int", "checkType": "range", "checkValue": [1, 16], "default": 1, "name": "批处理大小", "description": "批处理大小（BatchSize）表示在每次训练迭代中使用的样本数。较大的批处理大小可以加速训练，佉可能会导致内存问题。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "Validation Step，计算验证集Loss的间隔步数；为0时不开启验证，没有相关指标。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "训练过程最终要保存的Checkpoint个数，Checkpoint保存会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "训练过程中保存Checkpoint的间隔Step数。"}, {"key": "schedulerName", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "cosine", "name": "学习率调整计划", "description": "学习率调整计划（schedulerName），用于调整训练中学习率的变动方式。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.1], "default": 0.05, "name": "学习率预热步数占比", "description": "学习率预热步数占比（warmupRatio），指训练初始阶段，在学习率较低的情况下逐渐增加学习率的比例。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.001, 1], "default": 0.1, "name": "权重衰减数值", "description": "权重衰减数值（weightDecay），是一种正则化技术，用于帮助控制神经网络模型的复杂性以及减少过拟合的风险。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [8, 16, 32, 64, 128, 256], "default": 8, "name": "loraRank", "description": "LoRA策略中rank，数值越大lora参数越多。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096], "default": 2048, "name": "序列长度", "description": "序列长度（seqLen），单条样本的最大长度。如果训练数据较短，减少此项可以加快训练速度。"}], "supportIdleResource": false}]}]}, {"baseModel": "InternVL2", "model": "InternVL2-2B", "modelType": "ImageUnderstanding", "supportTrainMode": [{"trainMode": "SFT", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制训练过程中的迭代轮数。可以根据数据规模适当调整Epoch大小，建议设置在1-5之间，小数据量可以适当增大Epoch，让模型充分收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-10, 0.001], "default": 1e-05, "name": "学习率", "description": "学习率（LearningRate）是在梯度下降的过程中更新权重时的超参数，过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "batchSize", "type": "int", "checkType": "range", "checkValue": [1, 16], "default": 1, "name": "批处理大小", "description": "批处理大小（BatchSize）表示在每次训练迭代中使用的样本数。较大的批处理大小可以加速训练，佉可能会导致内存问题。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "Validation Step，计算验证集Loss的间隔步数；为0时不开启验证，没有相关指标。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "训练过程最终要保存的Checkpoint个数，Checkpoint保存会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "训练过程中保存Checkpoint的间隔Step数。"}, {"key": "schedulerName", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "cosine", "name": "学习率调整计划", "description": "学习率调整计划（schedulerName），用于调整训练中学习率的变动方式。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.1], "default": 0.05, "name": "学习率预热步数占比", "description": "学习率预热步数占比（warmupRatio），指训练初始阶段，在学习率较低的情况下逐渐增加学习率的比例。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.001, 1], "default": 0.1, "name": "权重衰减数值", "description": "权重衰减数值（weightDecay），是一种正则化技术，用于帮助控制神经网络模型的复杂性以及减少过拟合的风险。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096], "default": 2048, "name": "序列长度", "description": "序列长度（seqLen），单条样本的最大长度。如果训练数据较短，减少此项可以加快训练速度。"}], "supportIdleResource": false}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制训练过程中的迭代轮数。可以根据数据规模适当调整Epoch大小，建议设置在1-5之间，小数据量可以适当增大Epoch，让模型充分收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-10, 0.001], "default": 0.0001, "name": "学习率", "description": "学习率（LearningRate）是在梯度下降的过程中更新权重时的超参数，过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "batchSize", "type": "int", "checkType": "range", "checkValue": [1, 16], "default": 1, "name": "批处理大小", "description": "批处理大小（BatchSize）表示在每次训练迭代中使用的样本数。较大的批处理大小可以加速训练，佉可能会导致内存问题。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "Validation Step，计算验证集Loss的间隔步数；为0时不开启验证，没有相关指标。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "训练过程最终要保存的Checkpoint个数，Checkpoint保存会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "训练过程中保存Checkpoint的间隔Step数。"}, {"key": "schedulerName", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "cosine", "name": "学习率调整计划", "description": "学习率调整计划（schedulerName），用于调整训练中学习率的变动方式。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.1], "default": 0.05, "name": "学习率预热步数占比", "description": "学习率预热步数占比（warmupRatio），指训练初始阶段，在学习率较低的情况下逐渐增加学习率的比例。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.001, 1], "default": 0.1, "name": "权重衰减数值", "description": "权重衰减数值（weightDecay），是一种正则化技术，用于帮助控制神经网络模型的复杂性以及减少过拟合的风险。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [8, 16, 32, 64, 128, 256], "default": 8, "name": "loraRank", "description": "LoRA策略中rank，数值越大lora参数越多。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096], "default": 2048, "name": "序列长度", "description": "序列长度（seqLen），单条样本的最大长度。如果训练数据较短，减少此项可以加快训练速度。"}], "supportIdleResource": false}]}]}, {"baseModel": "Qwen2-VL", "model": "Qwen2-VL-7B", "modelType": "ImageUnderstanding", "supportTrainMode": [{"trainMode": "SFT", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制训练过程中的迭代轮数。可以根据数据规模适当调整Epoch大小，建议设置在1-5之间，小数据量可以适当增大Epoch，让模型充分收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-10, 0.001], "default": 1e-05, "name": "学习率", "description": "学习率（LearningRate）是在梯度下降的过程中更新权重时的超参数，过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "batchSize", "type": "int", "checkType": "range", "checkValue": [1, 16], "default": 1, "name": "批处理大小", "description": "批处理大小（BatchSize）表示在每次训练迭代中使用的样本数。较大的批处理大小可以加速训练，佉可能会导致内存问题。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "Validation Step，计算验证集Loss的间隔步数；为0时不开启验证，没有相关指标。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "训练过程最终要保存的Checkpoint个数，Checkpoint保存会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "训练过程中保存Checkpoint的间隔Step数。"}, {"key": "schedulerName", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "cosine", "name": "学习率调整计划", "description": "学习率调整计划（schedulerName），用于调整训练中学习率的变动方式。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.1], "default": 0.05, "name": "学习率预热步数占比", "description": "学习率预热步数占比（warmupRatio），指训练初始阶段，在学习率较低的情况下逐渐增加学习率的比例。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.001, 1], "default": 0.1, "name": "权重衰减数值", "description": "权重衰减数值（weightDecay），是一种正则化技术，用于帮助控制神经网络模型的复杂性以及减少过拟合的风险。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096], "default": 2048, "name": "序列长度", "description": "序列长度（seqLen），单条样本的最大长度。如果训练数据较短，减少此项可以加快训练速度。"}], "supportIdleResource": false}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制训练过程中的迭代轮数。可以根据数据规模适当调整Epoch大小，建议设置在1-5之间，小数据量可以适当增大Epoch，让模型充分收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-10, 0.001], "default": 0.0001, "name": "学习率", "description": "学习率（LearningRate）是在梯度下降的过程中更新权重时的超参数，过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "batchSize", "type": "int", "checkType": "range", "checkValue": [1, 16], "default": 1, "name": "批处理大小", "description": "批处理大小（BatchSize）表示在每次训练迭代中使用的样本数。较大的批处理大小可以加速训练，佉可能会导致内存问题。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "Validation Step，计算验证集Loss的间隔步数；为0时不开启验证，没有相关指标。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "训练过程最终要保存的Checkpoint个数，Checkpoint保存会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "训练过程中保存Checkpoint的间隔Step数。"}, {"key": "schedulerName", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "cosine", "name": "学习率调整计划", "description": "学习率调整计划（schedulerName），用于调整训练中学习率的变动方式。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.1], "default": 0.05, "name": "学习率预热步数占比", "description": "学习率预热步数占比（warmupRatio），指训练初始阶段，在学习率较低的情况下逐渐增加学习率的比例。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.001, 1], "default": 0.1, "name": "权重衰减数值", "description": "权重衰减数值（weightDecay），是一种正则化技术，用于帮助控制神经网络模型的复杂性以及减少过拟合的风险。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [8, 16, 32, 64, 128, 256], "default": 8, "name": "loraRank", "description": "LoRA策略中rank，数值越大lora参数越多。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096], "default": 2048, "name": "序列长度", "description": "序列长度（seqLen），单条样本的最大长度。如果训练数据较短，减少此项可以加快训练速度。"}], "supportIdleResource": false}]}]}, {"baseModel": "InternVL2", "model": "InternVL2-8B", "modelType": "ImageUnderstanding", "supportTrainMode": [{"trainMode": "SFT", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制训练过程中的迭代轮数。可以根据数据规模适当调整Epoch大小，建议设置在1-5之间，小数据量可以适当增大Epoch，让模型充分收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-10, 0.001], "default": 1e-05, "name": "学习率", "description": "学习率（LearningRate）是在梯度下降的过程中更新权重时的超参数，过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "batchSize", "type": "int", "checkType": "range", "checkValue": [1, 4], "default": 1, "name": "批处理大小", "description": "批处理大小（BatchSize）表示在每次训练迭代中使用的样本数。较大的批处理大小可以加速训练，佉可能会导致内存问题。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "Validation Step，计算验证集Loss的间隔步数；为0时不开启验证，没有相关指标。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "训练过程最终要保存的Checkpoint个数，Checkpoint保存会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "训练过程中保存Checkpoint的间隔Step数。"}, {"key": "schedulerName", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "cosine", "name": "学习率调整计划", "description": "学习率调整计划（schedulerName），用于调整训练中学习率的变动方式。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.1], "default": 0.05, "name": "学习率预热步数占比", "description": "学习率预热步数占比（warmupRatio），指训练初始阶段，在学习率较低的情况下逐渐增加学习率的比例。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.001, 1], "default": 0.1, "name": "权重衰减数值", "description": "权重衰减数值（weightDecay），是一种正则化技术，用于帮助控制神经网络模型的复杂性以及减少过拟合的风险。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096], "default": 2048, "name": "序列长度", "description": "序列长度（seqLen），单条样本的最大长度。如果训练数据较短，减少此项可以加快训练速度。"}], "supportIdleResource": false}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制训练过程中的迭代轮数。可以根据数据规模适当调整Epoch大小，建议设置在1-5之间，小数据量可以适当增大Epoch，让模型充分收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-10, 0.001], "default": 1e-05, "name": "学习率", "description": "学习率（LearningRate）是在梯度下降的过程中更新权重时的超参数，过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "batchSize", "type": "int", "checkType": "range", "checkValue": [1, 5], "default": 1, "name": "批处理大小", "description": "批处理大小（BatchSize）表示在每次训练迭代中使用的样本数。较大的批处理大小可以加速训练，佉可能会导致内存问题。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "Validation Step，计算验证集Loss的间隔步数；为0时不开启验证，没有相关指标。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "训练过程最终要保存的Checkpoint个数，Checkpoint保存会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "训练过程中保存Checkpoint的间隔Step数。"}, {"key": "schedulerName", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "cosine", "name": "学习率调整计划", "description": "学习率调整计划（schedulerName），用于调整训练中学习率的变动方式。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.1], "default": 0.05, "name": "学习率预热步数占比", "description": "学习率预热步数占比（warmupRatio），指训练初始阶段，在学习率较低的情况下逐渐增加学习率的比例。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.001, 1], "default": 0.1, "name": "权重衰减数值", "description": "权重衰减数值（weightDecay），是一种正则化技术，用于帮助控制神经网络模型的复杂性以及减少过拟合的风险。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096], "default": 2048, "name": "序列长度", "description": "序列长度（seqLen），单条样本的最大长度。如果训练数据较短，减少此项可以加快训练速度。"}], "supportIdleResource": false}]}]}, {"baseModel": "InternLM", "model": "InternLM-XComposer2.5", "modelType": "ImageUnderstanding", "supportTrainMode": [{"trainMode": "SFT", "supportParameterScale": [{"parameterScale": "FullFineTuning", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-10, 0.001], "default": 1e-05, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "batchSize", "type": "int", "checkType": "range", "checkValue": [1, 16], "default": 1, "name": "批处理大小", "description": "批处理大小（Batch Size）表示在每次训练迭代中使用的样本数。较大的批处理大小可以加速训练，却可能会导致显存问题。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "验证步数（Validation Step），计算验证集Loss的间隔步数；为0时不开启验证，没有相关指标。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "schedulerName", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "cosine", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.1], "default": 0.05, "name": "学习率预热步数占比", "description": "学习率预热步数占比（Warmup Ratio），指训练初始阶段，在学习率较低的情况下逐渐增加学习率的比例。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.001, 1], "default": 0.1, "name": "权重衰减数值", "description": "权重衰减数值（Weight Decay），是一种正则化技术，用于帮助控制神经网络模型的复杂性以及减少过拟合的风险。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096], "default": 2048, "name": "序列长度", "description": "序列长度（Sequence Length），单条样本的最大长度。该长度在模型的训练和推理过程中全部适用，超过该长度的部分将在推理时自动截断，单位为token。Sequence Length调大会增加生成时间，并且增加显存占用。"}], "supportIdleResource": false}, {"parameterScale": "LoRA", "supportHyperParameterConfig": [{"key": "epoch", "type": "int", "checkType": "range", "checkValue": [1, 50], "default": 1, "name": "迭代轮次", "description": "迭代轮次（Epoch），控制模型训练过程中遍历整个数据集的次数。建议设置在1-5之间，小数据集可增大Epoch以促进模型收敛。"}, {"key": "learningRate", "type": "float", "checkType": "range", "checkValue": [1e-10, 0.001], "default": 0.0001, "name": "学习率", "description": "学习率（Learning Rate），控制模型参数更新步长的速度。过高会导致模型难以收敛，过低则会导致模型收敛速度过慢，平台已给出默认推荐值，可根据经验调整。"}, {"key": "batchSize", "type": "int", "checkType": "range", "checkValue": [1, 16], "default": 1, "name": "批处理大小", "description": "批处理大小（Batch Size）表示在每次训练迭代中使用的样本数。较大的批处理大小可以加速训练，却可能会导致显存问题。"}, {"key": "validationStep", "type": "int", "checkType": "range", "checkValue": [0, 1000000], "default": 16, "name": "验证步数", "description": "Validation Step，计算验证集Loss的间隔步数；为0时不开启验证，没有相关指标。"}, {"key": "checkpointCount", "type": "int", "checkType": "range", "checkValue": [1, 10], "default": 1, "name": "Checkpoint保存个数", "description": "Checkpoint保存个数（Number of Checkpoint），训练过程最终要保存的Checkpoint个数。Checkpoint保存可以在系统故障时从最近的Checkpoint中恢复训练，但保存Checkpoint会增加训练时长。"}, {"key": "saveStep", "type": "int", "checkType": "range", "checkValue": [1, 50000], "default": 64, "name": "Checkpoint保存间隔数", "description": "Checkpoint保存间隔数（Checkpoint Interval），训练过程中保存Checkpoint的间隔Step数。间隔太短可能导致频繁的Checkpoint操作增加训练时长，间隔太长则可能在故障时丢失更多的数据。"}, {"key": "schedulerName", "type": "string", "checkType": "choice", "checkValue": ["linear", "cosine", "polynomial", "constant", "constant_with_warmup"], "default": "cosine", "name": "学习率调整计划", "description": "学习率调整计划（Scheduler Type），用于在训练过程中动态调整学习率，以优化模型的收敛速度和性能。根据模型的训练情况和任务需求，选择合适的学习率调整方式。"}, {"key": "warmupRatio", "type": "float", "checkType": "range", "checkValue": [0.01, 0.1], "default": 0.05, "name": "学习率预热步数占比", "description": "学习率预热步数占比（Warmup Ratio），指训练初始阶段，在学习率较低的情况下逐渐增加学习率的比例。"}, {"key": "weightDecay", "type": "float", "checkType": "range", "checkValue": [0.001, 1], "default": 0.1, "name": "权重衰减数值", "description": "权重衰减数值（Weight Decay），是一种正则化技术，用于帮助控制神经网络模型的复杂性以及减少过拟合的风险。"}, {"key": "loraRank", "type": "int", "checkType": "choice", "checkValue": [8, 16, 32, 64, 128, 256], "default": 8, "name": "loraRank", "description": "LoRA 策略中的秩（LoRA Rank），决定了微调过程中引入的低秩矩阵的复杂度。较小的秩可以减少参数数量，降低过拟合风险，但可能不足以捕捉任务所需的所有特征；较大的秩可能增强模型的表示能力，但会增加计算和存储负担。"}, {"key": "maxSeqLen", "type": "int", "checkType": "choice", "checkValue": [512, 1024, 2048, 4096], "default": 2048, "name": "序列长度", "description": "序列长度（Sequence Length），单条样本的最大长度。该长度在模型的训练和推理过程中全部适用，超过该长度的部分将在推理时自动截断，单位为token。Sequence Length调大会增加生成时间，并且增加显存占用。"}], "supportIdleResource": false}]}]}]}
"""
