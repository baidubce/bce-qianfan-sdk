{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pinecone-client qianfan tiktoken langchain pymupdf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pinecone初始化\n",
    "\n",
    "初始化pinecone，并创建pinecone索引（index）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "PINECONE_API_KEY = getpass.getpass(\"input your pinecone api key:\")\n",
    "PINECONE_ENV = input(\"input your env name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "pinecone.init(\n",
    "    api_key=PINECONE_API_KEY,\n",
    "    environment=PINECONE_ENV\n",
    ")\n",
    "\n",
    "index_name = \"qianfan-vdb\"\n",
    "\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    # we create a new index\n",
    "    pinecone.create_index(\n",
    "        name=index_name,\n",
    "        metric='euclidean',\n",
    "        dimension=384,  # 1536 dim of text-embedding-ada-002\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用千帆SDK前需要进行初始化鉴权"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "os.environ[\"QIANFAN_AK\"] = getpass.getpass(\"input your qianfan app ak:\")\n",
    "os.environ[\"QIANFAN_SK\"] = getpass.getpass(\"input your qianfan app sk:\")\n",
    "\n",
    "# s.environ[\"QIANFAN_ACCESS_KEY\"] iam\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "嵌入准备，实际上将text转换成高维向量的表示，Embeddings对象基于qianfan 实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import QianfanEmbeddingsEndpoint\n",
    "embeddings = QianfanEmbeddingsEndpoint(model=\"Embedding-V1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始化vectorstore，使用PyMuPDFLoader加载PDF文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 documents block loaded\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "\n",
    "loader = PyMuPDFLoader(\"./example_data/ai-paper.pdf\")\n",
    "documents = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=384, chunk_overlap=0, separators=[\"\\n\\n\", \"\\n\", \" \", \"\", \"。\", \"，\"])\n",
    "docs_spilts = text_splitter.split_documents(documents)\n",
    "print(f\"{len(docs_spilts)} documents block loaded\")\n",
    "\n",
    "pinecone_vdb = Pinecone.from_documents(docs_spilts, embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhonghanjun/anaconda3/lib/python3.11/site-packages/langchain/schema/vectorstore.py:313: UserWarning: Relevance scores must be between 0 and 1, got [(Document(page_content='放。DeepMind 指出，在对训练数据集进行扩展\\n时，需要重点关注数据集的质量管理，尤其是其中\\n的伦理和隐私等问题。\\n通信企业管理\\u2003 C-Enterprise\\u2003Management\\u2003 2023.6\\u2003 9', metadata={'author': 'CNKI', 'creationDate': \"D:20230718144804-08'00'\", 'creator': 'ReaderEx_DIS 2.3.0 Build 4031', 'file_path': './example_data/ai-paper.pdf', 'format': 'PDF 1.6', 'keywords': '', 'modDate': '', 'page': 3.0, 'producer': 'TTKN', 'source': './example_data/ai-paper.pdf', 'subject': '', 'title': '', 'total_pages': 7.0, 'trapped': ''}), 1.00852227), (Document(page_content='放。DeepMind 指出，在对训练数据集进行扩展\\n时，需要重点关注数据集的质量管理，尤其是其中\\n的伦理和隐私等问题。\\n通信企业管理\\u2003 C-Enterprise\\u2003Management\\u2003 2023.6\\u2003 9', metadata={'author': 'CNKI', 'creationDate': \"D:20230718144804-08'00'\", 'creator': 'ReaderEx_DIS 2.3.0 Build 4031', 'file_path': './example_data/ai-paper.pdf', 'format': 'PDF 1.6', 'keywords': '', 'modDate': '', 'page': 3.0, 'producer': 'TTKN', 'source': './example_data/ai-paper.pdf', 'subject': '', 'title': '', 'total_pages': 7.0, 'trapped': ''}), 1.00852227), (Document(page_content='Transformer 的生成式语言模型，它可以生成单词\\n以完成开放式文本任务，可以生成直接回答问题和\\n输入文档摘要。当模型越大、预训练数据越多样化\\n和全面，它在泛化到多个下游任务时的表现也越\\n好，即使有更少的训练示例。微软团队认为训练一\\n个大型集中的多任务模型并共享其能力跨多个任务\\n比为每个任务单独训练一个新模型更有效率。\\nDeepMind\\n2021 年 12 月，DeepMind 发 布 Gopher 模\\n型，该模型具有 2800 亿参数量。经过 152 个任务\\n的评估，Gopher 比当时最先进的语言模型提高了\\n大约 81% 的性能，特别是在知识密集领域，如事\\n实检测和常识上。\\n2022 年 4 月，\\n由 DeepMind 在 Gopher\\n基础上研究 Chinchilla 模型，其训练数据量是', metadata={'author': 'CNKI', 'creationDate': \"D:20230718144804-08'00'\", 'creator': 'ReaderEx_DIS 2.3.0 Build 4031', 'file_path': './example_data/ai-paper.pdf', 'format': 'PDF 1.6', 'keywords': '', 'modDate': '', 'page': 3.0, 'producer': 'TTKN', 'source': './example_data/ai-paper.pdf', 'subject': '', 'title': '', 'total_pages': 7.0, 'trapped': ''}), 1.035615205)]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#新建Retriever\n",
    "retriever = pinecone_vdb.as_retriever(search_type=\"similarity_score_threshold\", search_kwargs={'score_threshold': 0.5, \"k\":3 })\n",
    "matched_docs = retriever.get_relevant_documents(\"DeepMind\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新建LLM类对象\n",
    "from langchain.chat_models import QianfanChatEndpoint\n",
    "\n",
    "llm = QianfanChatEndpoint(model=\"ERNIE-Bot-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "CUSTOM_PROMPT = \"\"\"\n",
    "现在你是一个阅读理解机器人，你会阅读并深度理解我给你的文本内容并据此回答我所提出的问题。注意，我给出的问题是：{question} 你需要阅读理解的文本是：{context}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(llm, retriever=retriever, chain_type_kwargs={\"prompt\": PromptTemplate.from_template(CUSTOM_PROMPT)}, return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhonghanjun/anaconda3/lib/python3.11/site-packages/langchain/schema/vectorstore.py:313: UserWarning: Relevance scores must be between 0 and 1, got [(Document(page_content='勇在阿里云峰会上正式发布了大语言模型工具通义\\n千问，并宣布此语言模型会接入阿里旗下的所有业\\n务中。\\n百度 ERNIE\\n百 度 于 2019 年 3 月 发 布 预 训 练 模 型\\nERNIE1.0，2019 年 7 月 发 布 ERNIE2.0，2021\\n年 5 月开源四大预训练模型，包括多粒度语言知\\n识模型 ERNIE-Gram、超长文本双向建模预训练\\n模型 ERNIE-Doc、融合场景图知识的跨模态预训\\n练模型 ERNIE-ViL 和语言与视觉一体的预训练\\n模型 ERNIE-UNIMO，2021 年 12 月发布多语言\\n预训练模型 ERNIE-M。百度持续投入大模型的\\n技术创新与产业应用，布局了 NLP、CV、跨模态\\n等大模型，率先提出行业大模型，构建大模型工具\\n与平台，探索产品与社区，在企业端和用户端均有', metadata={'author': 'CNKI', 'creationDate': \"D:20230718144804-08'00'\", 'creator': 'ReaderEx_DIS 2.3.0 Build 4031', 'file_path': './example_data/ai-paper.pdf', 'format': 'PDF 1.6', 'keywords': '', 'modDate': '', 'page': 5.0, 'producer': 'TTKN', 'source': './example_data/ai-paper.pdf', 'subject': '', 'title': '', 'total_pages': 7.0, 'trapped': ''}), 1.07225263), (Document(page_content='勇在阿里云峰会上正式发布了大语言模型工具通义\\n千问，并宣布此语言模型会接入阿里旗下的所有业\\n务中。\\n百度 ERNIE\\n百 度 于 2019 年 3 月 发 布 预 训 练 模 型\\nERNIE1.0，2019 年 7 月 发 布 ERNIE2.0，2021\\n年 5 月开源四大预训练模型，包括多粒度语言知\\n识模型 ERNIE-Gram、超长文本双向建模预训练\\n模型 ERNIE-Doc、融合场景图知识的跨模态预训\\n练模型 ERNIE-ViL 和语言与视觉一体的预训练\\n模型 ERNIE-UNIMO，2021 年 12 月发布多语言\\n预训练模型 ERNIE-M。百度持续投入大模型的\\n技术创新与产业应用，布局了 NLP、CV、跨模态\\n等大模型，率先提出行业大模型，构建大模型工具\\n与平台，探索产品与社区，在企业端和用户端均有', metadata={'author': 'CNKI', 'creationDate': \"D:20230718144804-08'00'\", 'creator': 'ReaderEx_DIS 2.3.0 Build 4031', 'file_path': './example_data/ai-paper.pdf', 'format': 'PDF 1.6', 'keywords': '', 'modDate': '', 'page': 5.0, 'producer': 'TTKN', 'source': './example_data/ai-paper.pdf', 'subject': '', 'title': '', 'total_pages': 7.0, 'trapped': ''}), 1.07225263), (Document(page_content='|  特稿\\nFeature Article\\n不同程度的突破。训练参数为 100 亿。\\n文心 ERNIE 核心技术采用百度 NLP 自研的\\n基于知识增强的语义理解技术，其创新性地将大数\\n据预训练与多源丰富知识相结合，通过持续学习技\\n术，不断吸收海量文本数据中词汇、结构、语义等\\n方面的新知识，实现模型效果不断进化，显著提升\\n了产品智能化水平。基于文心 ERNIE 核心技术，\\n百度于 2023 年 2 月公开发布文心一言（ERNIE \\nBot）聊天机器人，这是百度全新一代知识增强大\\n语言模型，能够与人对话互动、回答问题、协助创\\n作，高效便捷地帮助人们获取信息、知识和灵感。\\n文心一言基于飞桨深度学习平台和文心知识增强大\\n模型，持续从海量数据和大规模知识中融合学习 ,\\n具备知识增强、检索增强和对话增强的技术特色。\\n目前已开放用户申请加入体验，但当前仅支持百度', metadata={'author': 'CNKI', 'creationDate': \"D:20230718144804-08'00'\", 'creator': 'ReaderEx_DIS 2.3.0 Build 4031', 'file_path': './example_data/ai-paper.pdf', 'format': 'PDF 1.6', 'keywords': '', 'modDate': '', 'page': 6.0, 'producer': 'TTKN', 'source': './example_data/ai-paper.pdf', 'subject': '', 'title': '', 'total_pages': 7.0, 'trapped': ''}), 1.07804)]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'ERNIE1.0是什么时候发布的？',\n",
       " 'result': '根据提供的文本内容，百度于2019年3月发布了预训练模型ERNIE1.0。因此，ERNIE1.0的发布时间是2019年3月。',\n",
       " 'source_documents': [Document(page_content='勇在阿里云峰会上正式发布了大语言模型工具通义\\n千问，并宣布此语言模型会接入阿里旗下的所有业\\n务中。\\n百度 ERNIE\\n百 度 于 2019 年 3 月 发 布 预 训 练 模 型\\nERNIE1.0，2019 年 7 月 发 布 ERNIE2.0，2021\\n年 5 月开源四大预训练模型，包括多粒度语言知\\n识模型 ERNIE-Gram、超长文本双向建模预训练\\n模型 ERNIE-Doc、融合场景图知识的跨模态预训\\n练模型 ERNIE-ViL 和语言与视觉一体的预训练\\n模型 ERNIE-UNIMO，2021 年 12 月发布多语言\\n预训练模型 ERNIE-M。百度持续投入大模型的\\n技术创新与产业应用，布局了 NLP、CV、跨模态\\n等大模型，率先提出行业大模型，构建大模型工具\\n与平台，探索产品与社区，在企业端和用户端均有', metadata={'author': 'CNKI', 'creationDate': \"D:20230718144804-08'00'\", 'creator': 'ReaderEx_DIS 2.3.0 Build 4031', 'file_path': './example_data/ai-paper.pdf', 'format': 'PDF 1.6', 'keywords': '', 'modDate': '', 'page': 5.0, 'producer': 'TTKN', 'source': './example_data/ai-paper.pdf', 'subject': '', 'title': '', 'total_pages': 7.0, 'trapped': ''}),\n",
       "  Document(page_content='勇在阿里云峰会上正式发布了大语言模型工具通义\\n千问，并宣布此语言模型会接入阿里旗下的所有业\\n务中。\\n百度 ERNIE\\n百 度 于 2019 年 3 月 发 布 预 训 练 模 型\\nERNIE1.0，2019 年 7 月 发 布 ERNIE2.0，2021\\n年 5 月开源四大预训练模型，包括多粒度语言知\\n识模型 ERNIE-Gram、超长文本双向建模预训练\\n模型 ERNIE-Doc、融合场景图知识的跨模态预训\\n练模型 ERNIE-ViL 和语言与视觉一体的预训练\\n模型 ERNIE-UNIMO，2021 年 12 月发布多语言\\n预训练模型 ERNIE-M。百度持续投入大模型的\\n技术创新与产业应用，布局了 NLP、CV、跨模态\\n等大模型，率先提出行业大模型，构建大模型工具\\n与平台，探索产品与社区，在企业端和用户端均有', metadata={'author': 'CNKI', 'creationDate': \"D:20230718144804-08'00'\", 'creator': 'ReaderEx_DIS 2.3.0 Build 4031', 'file_path': './example_data/ai-paper.pdf', 'format': 'PDF 1.6', 'keywords': '', 'modDate': '', 'page': 5.0, 'producer': 'TTKN', 'source': './example_data/ai-paper.pdf', 'subject': '', 'title': '', 'total_pages': 7.0, 'trapped': ''}),\n",
       "  Document(page_content='|  特稿\\nFeature Article\\n不同程度的突破。训练参数为 100 亿。\\n文心 ERNIE 核心技术采用百度 NLP 自研的\\n基于知识增强的语义理解技术，其创新性地将大数\\n据预训练与多源丰富知识相结合，通过持续学习技\\n术，不断吸收海量文本数据中词汇、结构、语义等\\n方面的新知识，实现模型效果不断进化，显著提升\\n了产品智能化水平。基于文心 ERNIE 核心技术，\\n百度于 2023 年 2 月公开发布文心一言（ERNIE \\nBot）聊天机器人，这是百度全新一代知识增强大\\n语言模型，能够与人对话互动、回答问题、协助创\\n作，高效便捷地帮助人们获取信息、知识和灵感。\\n文心一言基于飞桨深度学习平台和文心知识增强大\\n模型，持续从海量数据和大规模知识中融合学习 ,\\n具备知识增强、检索增强和对话增强的技术特色。\\n目前已开放用户申请加入体验，但当前仅支持百度', metadata={'author': 'CNKI', 'creationDate': \"D:20230718144804-08'00'\", 'creator': 'ReaderEx_DIS 2.3.0 Build 4031', 'file_path': './example_data/ai-paper.pdf', 'format': 'PDF 1.6', 'keywords': '', 'modDate': '', 'page': 6.0, 'producer': 'TTKN', 'source': './example_data/ai-paper.pdf', 'subject': '', 'title': '', 'total_pages': 7.0, 'trapped': ''})]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "query = \"ERNIE1.0是什么时候发布的？\" \n",
    "qa_chain({\"query\": query})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "58f7cb64c3a06383b7f18d2a11305edccbad427293a2b4afa7abe8bfc810d4bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
